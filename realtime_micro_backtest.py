#!/usr/bin/env python3
"""
å®æ—¶å¾®è§‚å›æµ‹ â€“ RexKing
é»˜è®¤å‚æ•°:
  long_th      = 0.7
  short_th     = 0.3
  hold_rows    = 20          # è¡Œæ•° = 20 æ¡æ•°æ®
  fee_rate     = 0.0005      # 0.05%
"""

import glob
import os
import json
import logging
from datetime import datetime
import pandas as pd
import numpy as np
import xgboost as xgb

# ---------- å‚æ•° ----------
LONG_TH   = 0.65  # å¤šå¤´é˜ˆå€¼
SHORT_TH  = 0.35  # ç©ºå¤´é˜ˆå€¼
HOLD_ROWS = 10    # æŒä»“æ­¥æ•°
FEE_RATE  = 0.001 # æ‰‹ç»­è´¹0.1%

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s %(levelname)s %(message)s"
)
logger = logging.getLogger("micro_backtest")

# ---------- å·¥å…· ----------
def latest_file(pattern: str) -> str:
    files = glob.glob(pattern)
    if not files:
        raise FileNotFoundError(f"No file match: {pattern}")
    return max(files, key=os.path.getctime)

# ---------- æ•°æ®ä¸æ¨¡å‹ ----------
feature_path = latest_file("data/analysis/micro_features_*.parquet")
model_path   = latest_file("xgb_realtime_*.bin")
feat_list_js = model_path.replace(".bin", ".json").replace("xgb_", "feature_list_")

logger.info(f"ğŸ”¹Features : {feature_path}")
logger.info(f"ğŸ”¹Model    : {model_path}")

df  = pd.read_parquet(feature_path).dropna().reset_index(drop=True)

with open(feat_list_js) as f:
    feats = json.load(f)

# ä¿è¯ç‰¹å¾åˆ—é¡ºåºä¸€è‡´ï¼Œç¼ºå¤±åˆ—å¡« 0
for col in feats:
    if col not in df.columns: df[col] = 0
X = df[feats].astype(float).fillna(0)

clf = xgb.XGBClassifier()
clf.load_model(model_path)
proba = clf.predict_proba(X)[:, 1]

# ---------- ç”Ÿæˆä¿¡å· ----------
df["prob"]   = proba
df["signal"] = 0
df.loc[df["prob"] >= LONG_TH , "signal"] =  1   # åšå¤š
df.loc[df["prob"] <= SHORT_TH, "signal"] = -1   # åšç©º

logger.info(f"ä¿¡å·ç»Ÿè®¡  å¤š:{(df.signal==1).sum()} ç©º:{(df.signal==-1).sum()}  æ— :{(df.signal==0).sum()}")

# ---------- äº¤æ˜“å›æµ‹ ----------
position     = 0
entry_price  = 0.0
entry_index  = -1
pnl_list     = []

for i, row in df.iterrows():
    price  = row["mid_price"]
    sig    = row["signal"]

    # å¹³ä»“æ¡ä»¶ï¼šæŒä»“è¾¾åˆ° HOLD_ROWS
    if position != 0 and (i - entry_index) >= HOLD_ROWS:
        ret = (price - entry_price)/entry_price if position==1 else (entry_price - price)/entry_price
        ret -= FEE_RATE*2               # è¿›+å‡º æ‰‹ç»­è´¹
        pnl_list.append(ret)
        position   = 0
        entry_price= 0
        entry_index= -1

    # å¼€ä»“æ¡ä»¶ï¼šå½“å‰æ— ä»“ä¸”å‡ºç°ä¿¡å·
    if position == 0 and sig != 0:
        position    = sig
        entry_price = price
        entry_index = i

# é¿å…æœ«å°¾æŒä»“æœªå¹³ï¼šæŒ‰æœ€æ–°ä»·å¼ºå¹³
if position != 0:
    price = df.iloc[-1]["mid_price"]
    ret   = (price - entry_price)/entry_price if position==1 else (entry_price - price)/entry_price
    ret  -= FEE_RATE*2
    pnl_list.append(ret)

# ---------- ç»“æœ ----------
pnl_series = pd.Series(pnl_list)
total_ret  = pnl_series.sum()
win_rate   = (pnl_series > 0).mean()
avg_ret    = pnl_series.mean() if len(pnl_series) else 0

logger.info("============= å›æµ‹ç»“æœ =============")
logger.info(f"äº¤æ˜“ç¬”æ•°  : {len(pnl_series)}")
logger.info(f"èƒœç‡      : {win_rate:.2%}")
logger.info(f"å¹³å‡æ”¶ç›Š  : {avg_ret:.4%}")
logger.info(f"ç´¯è®¡æ”¶ç›Š  : {total_ret:.4%}")
logger.info("====================================")

# ä¿å­˜ç»“æœ
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
results_df = pd.DataFrame({
    'trade_id': range(len(pnl_series)),
    'returns': pnl_series,
    'cumulative_returns': pnl_series.cumsum()
})
results_df.to_csv(f"micro_backtest_results_{timestamp}.csv", index=False)
logger.info(f"ç»“æœå·²ä¿å­˜: micro_backtest_results_{timestamp}.csv")

# ä¿å­˜ä¿¡å·æ•°æ®
signals_df = df[['timestamp', 'mid_price', 'prob', 'signal']].copy()
signals_df.to_csv(f"micro_signals_{timestamp}.csv", index=False)
logger.info(f"ä¿¡å·å·²ä¿å­˜: micro_signals_{timestamp}.csv") 
 