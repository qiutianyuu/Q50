#!/usr/bin/env python3
"""
ç®€åŒ–ç‰ˆ15m XGBoostè®­ç»ƒ - è¿‡æ‹Ÿåˆæ£€æµ‹
"""

import pandas as pd
import numpy as np
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_auc_score
import warnings
warnings.filterwarnings('ignore')

def main():
    print("ğŸ”§ ç®€åŒ–ç‰ˆ15m XGBoostè®­ç»ƒ - è¿‡æ‹Ÿåˆæ£€æµ‹")
    
    # è¯»å–ä¿®æ­£ç‰ˆç‰¹å¾æ•°æ®
    df = pd.read_parquet('/Users/qiutianyu/data/processed/features_15m_fixed.parquet')
    
    # å‡†å¤‡ç‰¹å¾
    exclude_cols = ['timestamp', 'open', 'high', 'low', 'close', 'volume', 'label', 'trend_1h', 'trend_4h']
    feature_cols = [col for col in df.columns if col not in exclude_cols and pd.api.types.is_numeric_dtype(df[col])]
    
    X = df[feature_cols].fillna(0)
    y = df['label']
    
    print(f"ç‰¹å¾æ•°é‡: {len(feature_cols)}")
    print(f"æ ·æœ¬æ•°é‡: {len(X)}")
    print(f"æ ‡ç­¾åˆ†å¸ƒ: {y.value_counts().to_dict()}")
    
    # æ—¶é—´æ’åº
    df_sorted = df.sort_values('timestamp').reset_index(drop=True)
    X_sorted = X.loc[df_sorted.index]
    y_sorted = y.loc[df_sorted.index]
    
    # ç®€å•çš„æ—¶åºåˆ†å‰²ï¼šå‰80%è®­ç»ƒï¼Œå20%æµ‹è¯•
    split_idx = int(len(df_sorted) * 0.8)
    
    X_train = X_sorted[:split_idx]
    y_train = y_sorted[:split_idx]
    X_test = X_sorted[split_idx:]
    y_test = y_sorted[split_idx:]
    
    print(f"è®­ç»ƒé›†: {len(X_train)} æ ·æœ¬")
    print(f"æµ‹è¯•é›†: {len(X_test)} æ ·æœ¬")
    
    # æ­£åˆ™åŒ–å‚æ•°ï¼ˆé¿å…è¿‡æ‹Ÿåˆï¼‰
    params = {
        'max_depth': 4,           # é™ä½æ·±åº¦
        'n_estimators': 200,      # å‡å°‘æ ‘æ•°é‡
        'learning_rate': 0.05,    # é™ä½å­¦ä¹ ç‡
        'subsample': 0.8,         # å­é‡‡æ ·
        'colsample_bytree': 0.8,  # ç‰¹å¾å­é‡‡æ ·
        'min_child_weight': 5,    # å¢åŠ æœ€å°å­èŠ‚ç‚¹æƒé‡
        'reg_alpha': 0.5,         # L1æ­£åˆ™åŒ–
        'reg_lambda': 2.0,        # L2æ­£åˆ™åŒ–
        'objective': 'binary:logistic',
        'eval_metric': 'auc',
        'use_label_encoder': False,
        'random_state': 42
    }
    
    # è®­ç»ƒæ¨¡å‹
    model = xgb.XGBClassifier(**params)
    model.fit(X_train, y_train, verbose=0)
    
    # è¯„ä¼°
    y_pred_proba_train = model.predict_proba(X_train)[:, 1]
    y_pred_proba_test = model.predict_proba(X_test)[:, 1]
    
    train_auc = roc_auc_score(y_train, y_pred_proba_train)
    test_auc = roc_auc_score(y_test, y_pred_proba_test)
    
    # è®¡ç®—è¿‡æ‹Ÿåˆç¨‹åº¦
    overfitting = train_auc - test_auc
    
    print(f"\nğŸ“Š è®­ç»ƒç»“æœ:")
    print(f"è®­ç»ƒAUC: {train_auc:.4f}")
    print(f"æµ‹è¯•AUC: {test_auc:.4f}")
    print(f"è¿‡æ‹Ÿåˆç¨‹åº¦: {overfitting:.4f}")
    
    # è¿‡æ‹Ÿåˆåˆ¤æ–­
    if overfitting > 0.05:
        print(f"âš ï¸ è­¦å‘Š: è¿‡æ‹Ÿåˆç¨‹åº¦ {overfitting:.4f} > 0.05ï¼Œæ¨¡å‹å¯èƒ½è¿‡æ‹Ÿåˆ")
    elif overfitting > 0.02:
        print(f"âš ï¸ æ³¨æ„: è¿‡æ‹Ÿåˆç¨‹åº¦ {overfitting:.4f} > 0.02ï¼Œéœ€è¦å…³æ³¨")
    else:
        print(f"âœ… è¿‡æ‹Ÿåˆæ§åˆ¶è‰¯å¥½: {overfitting:.4f} â‰¤ 0.02")
    
    # é«˜ç½®ä¿¡åº¦é¢„æµ‹åˆ†æ
    high_conf_mask_test = (y_pred_proba_test > 0.8) | (y_pred_proba_test < 0.2)
    
    if high_conf_mask_test.sum() > 0:
        high_conf_auc = roc_auc_score(y_test[high_conf_mask_test], y_pred_proba_test[high_conf_mask_test])
        high_conf_acc = ((y_pred_proba_test[high_conf_mask_test] > 0.5) == y_test[high_conf_mask_test]).mean()
        
        print(f"\nğŸ¯ é«˜ç½®ä¿¡åº¦é¢„æµ‹åˆ†æ:")
        print(f"é«˜ç½®ä¿¡åº¦æ ·æœ¬æ•°: {high_conf_mask_test.sum()}")
        print(f"é«˜ç½®ä¿¡åº¦AUC: {high_conf_auc:.4f}")
        print(f"é«˜ç½®ä¿¡åº¦å‡†ç¡®ç‡: {high_conf_acc:.4f}")
    
    # ä¿å­˜æ¨¡å‹
    model.save_model('xgb_15m_simple.bin')
    print(f"\nâœ… æ¨¡å‹å·²ä¿å­˜: xgb_15m_simple.bin")
    
    # ä¿å­˜é¢„æµ‹ç»“æœç”¨äºåç»­åˆ†æ
    results_df = pd.DataFrame({
        'timestamp': df_sorted['timestamp'][split_idx:],
        'true_label': y_test,
        'pred_proba': y_pred_proba_test,
        'pred_label': (y_pred_proba_test > 0.5).astype(int)
    })
    
    results_df.to_csv('xgb_15m_simple_results.csv', index=False)
    print("âœ… é¢„æµ‹ç»“æœå·²ä¿å­˜: xgb_15m_simple_results.csv")
    
    return model, test_auc, overfitting

if __name__ == "__main__":
    main() 