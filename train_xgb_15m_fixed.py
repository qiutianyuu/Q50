#!/usr/bin/env python3
"""
ä¿®æ­£ç‰ˆ15m XGBoostè®­ç»ƒ - é¿å…è¿‡æ‹Ÿåˆ
ä½¿ç”¨æ­£åˆ™åŒ–ã€æ—©åœã€Walk-forwardéªŒè¯
"""

import pandas as pd
import numpy as np
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_auc_score, classification_report
import warnings
warnings.filterwarnings('ignore')

def train_with_walk_forward():
    """ä½¿ç”¨Walk-forwardéªŒè¯è®­ç»ƒæ¨¡å‹"""
    print("ğŸš€ å¼€å§‹Walk-forwardéªŒè¯è®­ç»ƒ...")
    
    # è¯»å–ä¿®æ­£ç‰ˆç‰¹å¾æ•°æ®
    df = pd.read_parquet('/Users/qiutianyu/data/processed/features_15m_fixed.parquet')
    
    # å‡†å¤‡ç‰¹å¾
    exclude_cols = ['timestamp', 'open', 'high', 'low', 'close', 'volume', 'label', 'trend_1h', 'trend_4h']
    feature_cols = [col for col in df.columns if col not in exclude_cols and pd.api.types.is_numeric_dtype(df[col])]
    
    X = df[feature_cols].fillna(0)
    y = df['label']
    
    print(f"ç‰¹å¾æ•°é‡: {len(feature_cols)}")
    print(f"æ ·æœ¬æ•°é‡: {len(X)}")
    print(f"æ ‡ç­¾åˆ†å¸ƒ: {y.value_counts().to_dict()}")
    
    # æ—¶é—´æ’åº
    df_sorted = df.sort_values('timestamp').reset_index(drop=True)
    X_sorted = X.loc[df_sorted.index]
    y_sorted = y.loc[df_sorted.index]
    
    # Walk-forwardå‚æ•°
    train_days = 180  # 6ä¸ªæœˆè®­ç»ƒ
    test_days = 30    # 1ä¸ªæœˆæµ‹è¯•
    step_days = 30    # æ¯30å¤©å‘å‰æ»šåŠ¨
    
    # è®¡ç®—æ—¶é—´çª—å£
    total_days = (df_sorted['timestamp'].max() - df_sorted['timestamp'].min()).days
    print(f"æ€»æ—¶é—´è·¨åº¦: {total_days}å¤©")
    
    # ç”Ÿæˆæ—¶é—´çª—å£
    windows = []
    start_date = df_sorted['timestamp'].min()
    
    while True:
        train_start = start_date
        train_end = train_start + pd.Timedelta(days=train_days)
        test_start = train_end
        test_end = test_start + pd.Timedelta(days=test_days)
        
        if test_end > df_sorted['timestamp'].max():
            break
            
        windows.append({
            'train_start': train_start,
            'train_end': train_end,
            'test_start': test_start,
            'test_end': test_end
        })
        
        start_date += pd.Timedelta(days=step_days)
    
    print(f"ç”Ÿæˆ {len(windows)} ä¸ªæ—¶é—´çª—å£")
    
    # å­˜å‚¨æ¯ä¸ªçª—å£çš„ç»“æœ
    results = []
    
    # æ­£åˆ™åŒ–å‚æ•°ï¼ˆé¿å…è¿‡æ‹Ÿåˆï¼‰
    params = {
        'max_depth': 4,           # é™ä½æ·±åº¦
        'n_estimators': 200,      # å‡å°‘æ ‘æ•°é‡
        'learning_rate': 0.05,    # é™ä½å­¦ä¹ ç‡
        'subsample': 0.8,         # å­é‡‡æ ·
        'colsample_bytree': 0.8,  # ç‰¹å¾å­é‡‡æ ·
        'min_child_weight': 5,    # å¢åŠ æœ€å°å­èŠ‚ç‚¹æƒé‡
        'reg_alpha': 0.5,         # L1æ­£åˆ™åŒ–
        'reg_lambda': 2.0,        # L2æ­£åˆ™åŒ–
        'objective': 'binary:logistic',
        'eval_metric': 'auc',
        'use_label_encoder': False,
        'random_state': 42
    }
    
    for i, window in enumerate(windows):
        print(f"\nğŸ“Š çª—å£ {i+1}/{len(windows)}: {window['train_start'].date()} - {window['test_end'].date()}")
        
        # åˆ†å‰²è®­ç»ƒé›†å’Œæµ‹è¯•é›†
        train_mask = (df_sorted['timestamp'] >= window['train_start']) & (df_sorted['timestamp'] < window['train_end'])
        test_mask = (df_sorted['timestamp'] >= window['test_start']) & (df_sorted['timestamp'] < window['test_end'])
        
        X_train = X_sorted[train_mask]
        y_train = y_sorted[train_mask]
        X_test = X_sorted[test_mask]
        y_test = y_sorted[test_mask]
        
        if len(X_train) < 1000 or len(X_test) < 100:
            print(f"âš ï¸ çª—å£ {i+1} æ ·æœ¬ä¸è¶³ï¼Œè·³è¿‡")
            continue
        
        print(f"è®­ç»ƒé›†: {len(X_train)} æ ·æœ¬")
        print(f"æµ‹è¯•é›†: {len(X_test)} æ ·æœ¬")
        
        # è®­ç»ƒæ¨¡å‹ï¼ˆä½¿ç”¨æ­£åˆ™åŒ–ï¼‰
        model = xgb.XGBClassifier(**params)
        model.fit(X_train, y_train, verbose=0)
        
        # è¯„ä¼°
        y_pred_proba = model.predict_proba(X_test)[:, 1]
        y_pred = model.predict(X_test)
        
        train_auc = roc_auc_score(y_train, model.predict_proba(X_train)[:, 1])
        test_auc = roc_auc_score(y_test, y_pred_proba)
        
        # è®¡ç®—è¿‡æ‹Ÿåˆç¨‹åº¦
        overfitting = train_auc - test_auc
        
        # é«˜ç½®ä¿¡åº¦é¢„æµ‹
        high_conf_mask = (y_pred_proba > 0.8) | (y_pred_proba < 0.2)
        high_conf_auc = 0
        high_conf_acc = 0
        high_conf_count = 0
        
        if high_conf_mask.sum() > 0:
            high_conf_auc = roc_auc_score(y_test[high_conf_mask], y_pred_proba[high_conf_mask])
            high_conf_acc = (y_pred[high_conf_mask] == y_test[high_conf_mask]).mean()
            high_conf_count = high_conf_mask.sum()
        
        # è®°å½•ç»“æœ
        window_result = {
            'window': i+1,
            'train_start': window['train_start'],
            'test_end': window['test_end'],
            'train_samples': len(X_train),
            'test_samples': len(X_test),
            'train_auc': train_auc,
            'test_auc': test_auc,
            'overfitting': overfitting,
            'high_conf_auc': high_conf_auc,
            'high_conf_acc': high_conf_acc,
            'high_conf_count': high_conf_count
        }
        
        results.append(window_result)
        
        print(f"è®­ç»ƒAUC: {train_auc:.4f}")
        print(f"æµ‹è¯•AUC: {test_auc:.4f}")
        print(f"è¿‡æ‹Ÿåˆç¨‹åº¦: {overfitting:.4f}")
        print(f"é«˜ç½®ä¿¡åº¦AUC: {high_conf_auc:.4f}")
        print(f"é«˜ç½®ä¿¡åº¦å‡†ç¡®ç‡: {high_conf_acc:.4f}")
    
    # åˆ†æç»“æœ
    if results:
        results_df = pd.DataFrame(results)
        
        print(f"\nğŸ“Š Walk-forwardéªŒè¯ç»“æœæ€»ç»“:")
        print(f"æ€»çª—å£æ•°: {len(results_df)}")
        print(f"å¹³å‡æµ‹è¯•AUC: {results_df['test_auc'].mean():.4f} Â± {results_df['test_auc'].std():.4f}")
        print(f"å¹³å‡è¿‡æ‹Ÿåˆç¨‹åº¦: {results_df['overfitting'].mean():.4f} Â± {results_df['overfitting'].std():.4f}")
        print(f"å¹³å‡é«˜ç½®ä¿¡åº¦AUC: {results_df['high_conf_auc'].mean():.4f} Â± {results_df['high_conf_auc'].std():.4f}")
        print(f"å¹³å‡é«˜ç½®ä¿¡åº¦å‡†ç¡®ç‡: {results_df['high_conf_acc'].mean():.4f} Â± {results_df['high_conf_acc'].std():.4f}")
        
        # ä¿å­˜ç»“æœ
        results_df.to_csv('walk_forward_15m_results.csv', index=False)
        print("âœ… Walk-forwardç»“æœå·²ä¿å­˜: walk_forward_15m_results.csv")
        
        # æ£€æŸ¥è¿‡æ‹Ÿåˆ
        avg_overfitting = results_df['overfitting'].mean()
        if avg_overfitting > 0.05:
            print(f"âš ï¸ è­¦å‘Š: å¹³å‡è¿‡æ‹Ÿåˆç¨‹åº¦ {avg_overfitting:.4f} > 0.05ï¼Œå»ºè®®è¿›ä¸€æ­¥æ­£åˆ™åŒ–")
        else:
            print(f"âœ… è¿‡æ‹Ÿåˆæ§åˆ¶è‰¯å¥½: {avg_overfitting:.4f} â‰¤ 0.05")
        
        return results_df
    else:
        print("âŒ æ²¡æœ‰æœ‰æ•ˆçš„éªŒè¯çª—å£")
        return None

def train_final_model():
    """è®­ç»ƒæœ€ç»ˆæ¨¡å‹ï¼ˆä½¿ç”¨å…¨éƒ¨æ•°æ®ï¼‰"""
    print("\nğŸ¯ è®­ç»ƒæœ€ç»ˆæ¨¡å‹...")
    
    # è¯»å–æ•°æ®
    df = pd.read_parquet('/Users/qiutianyu/data/processed/features_15m_fixed.parquet')
    
    # å‡†å¤‡ç‰¹å¾
    exclude_cols = ['timestamp', 'open', 'high', 'low', 'close', 'volume', 'label', 'trend_1h', 'trend_4h']
    feature_cols = [col for col in df.columns if col not in exclude_cols and pd.api.types.is_numeric_dtype(df[col])]
    
    X = df[feature_cols].fillna(0)
    y = df['label']
    
    # åˆ†å‰²æ•°æ®
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
    
    # æ­£åˆ™åŒ–å‚æ•°
    params = {
        'max_depth': 4,
        'n_estimators': 200,
        'learning_rate': 0.05,
        'subsample': 0.8,
        'colsample_bytree': 0.8,
        'min_child_weight': 5,
        'reg_alpha': 0.5,
        'reg_lambda': 2.0,
        'objective': 'binary:logistic',
        'eval_metric': 'auc',
        'use_label_encoder': False,
        'random_state': 42
    }
    
    # è®­ç»ƒæ¨¡å‹
    model = xgb.XGBClassifier(**params)
    model.fit(X_train, y_train, verbose=0)
    
    # è¯„ä¼°
    y_pred_proba = model.predict_proba(X_test)[:, 1]
    y_pred = model.predict(X_test)
    
    train_auc = roc_auc_score(y_train, model.predict_proba(X_train)[:, 1])
    test_auc = roc_auc_score(y_test, y_pred_proba)
    
    print(f"è®­ç»ƒAUC: {train_auc:.4f}")
    print(f"æµ‹è¯•AUC: {test_auc:.4f}")
    print(f"è¿‡æ‹Ÿåˆç¨‹åº¦: {train_auc - test_auc:.4f}")
    
    # ä¿å­˜æ¨¡å‹
    model.save_model('xgb_15m_fixed.bin')
    print("âœ… æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜: xgb_15m_fixed.bin")
    
    return model, test_auc

def main():
    print("ğŸ”§ ä¿®æ­£ç‰ˆ15m XGBoostè®­ç»ƒ - é¿å…è¿‡æ‹Ÿåˆ")
    
    # Walk-forwardéªŒè¯
    results = train_with_walk_forward()
    
    # è®­ç»ƒæœ€ç»ˆæ¨¡å‹
    model, final_auc = train_final_model()
    
    print(f"\nğŸ‰ è®­ç»ƒå®Œæˆ! æœ€ç»ˆæµ‹è¯•AUC: {final_auc:.4f}")

if __name__ == "__main__":
    main() 