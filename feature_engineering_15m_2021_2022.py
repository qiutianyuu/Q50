#!/usr/bin/env python3
"""
RexKing â€“ Feature Engineering 15m for 2021-2022 Data

è¯»å–å·²å¤„ç†çš„ 2021-2022 15m K çº¿, è®¡ç®—ä¸€æ½å­æŠ€æœ¯æŒ‡æ ‡ + whale æ»šåŠ¨æŒ‡æ ‡,
ç”ŸæˆäºŒåˆ†ç±»æ ‡ç­¾(ä¸‹ä¸€æ ¹ K çº¿æ¶¨/è·Œ), ä¿å­˜ä¸º Parquet & CSV.
"""

import pandas as pd
import numpy as np
from pathlib import Path
from ta.trend import ADXIndicator, MACD, EMAIndicator
from ta.momentum import RSIIndicator, StochasticOscillator
from ta.volatility import BollingerBands, AverageTrueRange

# ---------- è·¯å¾„é…ç½® ----------
DATA_DIR = Path("data")  # ä½¿ç”¨ç›¸å¯¹è·¯å¾„
KL_FILE  = DATA_DIR / "merged_15m_2021_2022.parquet"
W1_FILE  = Path("/Users/qiutianyu/ETHUSDT-w1/w1_2021_2022.csv")  # éœ€è¦ç¡®è®¤è·¯å¾„
FUND_OI_FILE = DATA_DIR / "funding_oi_1h_2021_2022.parquet"  # éœ€è¦ç¡®è®¤è·¯å¾„
OUTPUT_FILE = DATA_DIR / "features_15m_2021_2022.parquet"

# ---------- æŠ€æœ¯æŒ‡æ ‡ ----------
def add_ta_features(df: pd.DataFrame) -> pd.DataFrame:
    hi, lo, close, vol = df["high"], df["low"], df["close"], df["volume"]

    # è¶‹åŠ¿æŒ‡æ ‡
    df["adx_14"]  = ADXIndicator(hi, lo, close, window=14).adx()
    df["rsi_14"]  = RSIIndicator(close, window=14).rsi()

    macd = MACD(close)
    df["macd_diff"] = macd.macd_diff()

    stoch = StochasticOscillator(hi, lo, close, window=14, smooth_window=3)
    df["stoch_k"] = stoch.stoch()
    df["stoch_d"] = stoch.stoch_signal()

    bb = BollingerBands(close, window=20, window_dev=2)
    df["bb_width"]   = (bb.bollinger_hband() - bb.bollinger_lband()) / close
    df["bb_percent"] = bb.bollinger_pband()

    atr = AverageTrueRange(hi, lo, close, window=14)
    df["atr_norm"] = atr.average_true_range() / close

    # åŠ¨é‡æŒ‡æ ‡
    df["ret_1"]  = close.pct_change()
    df["ret_3"]  = close.pct_change(3)
    df["ret_6"]  = close.pct_change(6)
    df["ret_12"] = close.pct_change(12)  # 3å°æ—¶
    df["ret_24"] = close.pct_change(24)  # 6å°æ—¶
    df["ret_48"] = close.pct_change(48)  # 12å°æ—¶
    
    # æ³¢åŠ¨ç‡æŒ‡æ ‡
    df["volatility_10"] = close.pct_change().rolling(10).std()
    df["volatility_24"] = close.pct_change().rolling(24).std()
    df["volatility_48"] = close.pct_change().rolling(48).std()

    # EMA æ–œç‡
    ema_50 = EMAIndicator(close, window=50).ema_indicator()
    ema_200 = EMAIndicator(close, window=200).ema_indicator()
    df["ema_50_slope"] = ema_50.pct_change(4)  # 1å°æ—¶æ–œç‡
    df["ema_200_slope"] = ema_200.pct_change(16)  # 4å°æ—¶æ–œç‡
    df["ema_50_200_ratio"] = ema_50 / ema_200

    # æˆäº¤é‡æŒ‡æ ‡
    df["vol_ma20"] = vol.rolling(20).mean()
    df["vol_ratio"] = vol / df["vol_ma20"]
    df["vol_ma50"] = vol.rolling(50).mean()
    df["vol_ratio_50"] = vol / df["vol_ma50"]

    return df

# ---------- æ—¶é—´ç‰¹å¾ ----------
def add_time_features(df: pd.DataFrame) -> pd.DataFrame:
    df["hour"] = df["timestamp"].dt.hour
    df["weekday"] = df["timestamp"].dt.weekday
    df["month"] = df["timestamp"].dt.month
    
    # æ—¶é—´å‘¨æœŸç‰¹å¾
    df["is_asia_session"] = ((df["hour"] >= 0) & (df["hour"] < 8)).astype(int)
    df["is_london_session"] = ((df["hour"] >= 8) & (df["hour"] < 16)).astype(int)
    df["is_ny_session"] = ((df["hour"] >= 13) & (df["hour"] < 21)).astype(int)
    
    return df

# ---------- Funding & OI ç‰¹å¾ ----------
def add_funding_oi_features(df: pd.DataFrame) -> pd.DataFrame:
    if FUND_OI_FILE.exists():
        f = pd.read_parquet(FUND_OI_FILE)
        f['timestamp'] = pd.to_datetime(f['timestamp'], utc=True)
        
        # ç¡®ä¿ä¸»æ•°æ®ä¹Ÿæœ‰UTCæ—¶åŒº
        df['timestamp'] = pd.to_datetime(df['timestamp'], utc=True)
        
        # Funding z-scoreï¼ˆæ»šåŠ¨7å¤©ï¼‰
        f['funding_z'] = (
            (f['funding'] - f['funding'].rolling(168).mean())
            / f['funding'].rolling(168).std()
        )
        
        # æŒ‰å°æ—¶å…ˆforward-fillå†merge_asof
        df = pd.merge_asof(
            df.sort_values('timestamp'),
            f.sort_values('timestamp'),
            on='timestamp', direction='backward'
        )
        
        # OIå˜åŒ–ç‡
        df['oi_chg_6h'] = f['oi'].pct_change(6)
        df['oi_chg_24h'] = f['oi'].pct_change(24)
        
        # æ·»åŠ æ¨¡å‹éœ€è¦çš„åŸå§‹ç‰¹å¾
        df['funding'] = f['funding']
        df['oi'] = f['oi']
        
        # å¡«å……NaN
        df[['funding_z', 'oi_chg_6h', 'oi_chg_24h', 'funding', 'oi']] = df[['funding_z', 'oi_chg_6h', 'oi_chg_24h', 'funding', 'oi']].fillna(0)
    else:
        # æ–‡ä»¶ä¸å­˜åœ¨æ—¶å¡«0
        df[['funding_z', 'oi_chg_6h', 'oi_chg_24h', 'funding', 'oi']] = 0
    return df

# ---------- Whale ä¿¡å· ----------
def add_whale_features(df: pd.DataFrame) -> pd.DataFrame:
    # åˆå§‹åŒ–æ‰€æœ‰whaleç‰¹å¾ä¸º0
    whale_cols = ["w1_zscore", "w1_cnt_6h", "w1_cnt_12h", "w1_cnt_24h", 
                  "w1_val_6h", "w1_val_12h", "w1_val_24h",
                  "w1_cnt_6h_norm", "w1_val_6h_norm", "whale_dir", 
                  "whale_dir_6h", "whale_dir_12h"]
    for col in whale_cols:
        df[col] = 0
    
    if W1_FILE.exists():
        w1 = pd.read_csv(W1_FILE, parse_dates=["timestamp"])
        w1["timestamp"] = pd.to_datetime(w1["timestamp"], utc=True)
        
        # æ£€æŸ¥whaleæ•°æ®æ˜¯å¦è¶³å¤Ÿ
        if len(w1) > 10:  # è‡³å°‘éœ€è¦10ä¸ªæ•°æ®ç‚¹
            df = df.merge(
                w1[["timestamp", "count", "value", "w1_zscore"]],
                on="timestamp", how="left"
            )

            df[["count", "value", "w1_zscore"]] = df[["count", "value", "w1_zscore"]].fillna(0)
            
            # æ»šåŠ¨çª—å£
            df["w1_cnt_6h"]   = df["count"].rolling(24, min_periods=1).sum()   # 6å°æ—¶ (24æ ¹15m)
            df["w1_cnt_12h"]  = df["count"].rolling(48, min_periods=1).sum()   # 12å°æ—¶ (48æ ¹15m)
            df["w1_cnt_24h"]  = df["count"].rolling(96, min_periods=1).sum()   # 24å°æ—¶ (96æ ¹15m)
            
            df["w1_val_6h"]   = df["value"].rolling(24, min_periods=1).sum()
            df["w1_val_12h"]  = df["value"].rolling(48, min_periods=1).sum()
            df["w1_val_24h"]  = df["value"].rolling(96, min_periods=1).sum()
            
            # æ ‡å‡†åŒ–
            df["w1_cnt_6h_norm"] = df["w1_cnt_6h"] / df["w1_cnt_6h"].rolling(96).mean()
            df["w1_val_6h_norm"] = df["w1_val_6h"] / df["w1_val_6h"].rolling(96).mean()
            
            # Whale direction
            df["whale_dir"] = np.sign(df["value"])  # 1=æµå…¥, -1=æµå‡º, 0=æ— å˜åŒ–
            df["whale_dir_6h"] = df["whale_dir"].rolling(24, min_periods=1).sum()   # 6å°æ—¶å‡€æ–¹å‘
            df["whale_dir_12h"] = df["whale_dir"].rolling(48, min_periods=1).sum()  # 12å°æ—¶å‡€æ–¹å‘
        else:
            print(f"âš ï¸ Whaleæ•°æ®ä¸è¶³ ({len(w1)}è¡Œ)ï¼Œä½¿ç”¨é»˜è®¤å€¼")
    else:
        print("âš ï¸ Whaleæ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤å€¼")
    
    return df

# ---------- æ ‡ç­¾ ----------
def add_label(df: pd.DataFrame) -> pd.DataFrame:
    """ä½¿ç”¨ç®€å•çš„æœªæ¥ä»·æ ¼æ ‡ç­¾"""
    df["label"] = (df["close"].shift(-1) > df["close"]).astype(int)
    return df

# ---------- ä¸»æµç¨‹ ----------
def main():
    print(f"ğŸ“¥ è¯»å– {KL_FILE.name} ...")
    df = pd.read_parquet(KL_FILE)
    # ä¿®æ­£ dtype æ£€æŸ¥ï¼Œå…¼å®¹ pandas æ‰©å±•ç±»å‹
    if not pd.api.types.is_datetime64_any_dtype(df["timestamp"]):
        df["timestamp"] = pd.to_datetime(df["timestamp"], utc=True)
    df = df.sort_values("timestamp").reset_index(drop=True)

    print("âœ¨ è®¡ç®—æŠ€æœ¯æŒ‡æ ‡ ...")
    df = add_ta_features(df)

    print("â° æ·»åŠ æ—¶é—´ç‰¹å¾ ...")
    df = add_time_features(df)

    print("ğŸ’° æ·»åŠ Funding & OIç‰¹å¾ ...")
    df = add_funding_oi_features(df)

    print("ğŸ‹ æ·»åŠ Whaleç‰¹å¾ ...")
    df = add_whale_features(df)

    print("ğŸ·ï¸ ç”Ÿæˆæ ‡ç­¾ ...")
    df = add_label(df)

    # åˆ é™¤åŒ…å«NaNçš„è¡Œ
    print("ğŸ§¹ æ¸…ç†æ•°æ® ...")
    initial_len = len(df)
    df = df.dropna().reset_index(drop=True)
    print(f"åˆ é™¤NaNå: {len(df)} è¡Œ (åˆ é™¤äº† {initial_len - len(df)} è¡Œ)")

    # ä¿å­˜ç»“æœ
    print(f"ğŸ’¾ ä¿å­˜åˆ° {OUTPUT_FILE} ...")
    df.to_parquet(OUTPUT_FILE, compression='zstd', index=False)
    df.to_csv(OUTPUT_FILE.with_suffix('.csv'), index=False)

    print("âœ… ç‰¹å¾å·¥ç¨‹å®Œæˆ!")
    print(f"ğŸ“Š æœ€ç»ˆæ•°æ®: {df.shape}")
    print(f"ğŸ“… æ—¶é—´èŒƒå›´: {df['timestamp'].min()} åˆ° {df['timestamp'].max()}")
    print(f"ğŸ·ï¸ æ ‡ç­¾åˆ†å¸ƒ: {df['label'].value_counts().to_dict()}")

if __name__ == "__main__":
    main() 