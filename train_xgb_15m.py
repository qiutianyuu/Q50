#!/usr/bin/env python3
"""
RexKing â€“ XGBoost Training 15m (Walk-Forward)

è¯»å– 15m ç‰¹å¾æ•°æ®, ä½¿ç”¨walk-forwardéªŒè¯è®­ç»ƒXGBoostæ¨¡å‹, è¾“å‡ºAUCå’ŒSHAPé‡è¦æ€§.
"""

import pandas as pd
import numpy as np
from pathlib import Path
import xgboost as xgb
from sklearn.metrics import roc_auc_score, classification_report
import shap
import warnings
warnings.filterwarnings('ignore')

# ---------- è·¯å¾„é…ç½® ----------
DATA_DIR = Path("/Users/qiutianyu/data/processed")
FEATURES_FILE = DATA_DIR / "features_15m_2023_2025.parquet"
MODEL_FILE = "xgb_15m_model.bin"

# ---------- æ•°æ®é¢„å¤„ç† ----------
def prepare_data(df: pd.DataFrame) -> tuple:
    """å‡†å¤‡è®­ç»ƒæ•°æ®"""
    # è¿‡æ»¤æ•°å€¼ç‰¹å¾
    exclude_cols = ['timestamp', 'open', 'high', 'low', 'close', 'volume', 'label', 'trend_1h', 'trend_4h']
    feature_cols = [col for col in df.columns if col not in exclude_cols and pd.api.types.is_numeric_dtype(df[col])]
    
    X = df[feature_cols].fillna(0)
    y = df['label']
    
    print(f"ç‰¹å¾æ•°é‡: {len(feature_cols)}")
    print(f"æ ·æœ¬æ•°é‡: {len(X)}")
    print(f"æ ‡ç­¾åˆ†å¸ƒ: {y.value_counts().to_dict()}")
    
    return X, y, feature_cols, feature_cols

# ---------- Walk-Forward åˆ†å‰² ----------
def create_walk_forward_splits(df: pd.DataFrame, train_days: int = 180, test_days: int = 30, offset_days: int = 30):
    """åˆ›å»ºwalk-forwardåˆ†å‰²ï¼ˆæ»šåŠ¨çª—å£ï¼‰"""
    df = df.sort_values('timestamp').reset_index(drop=True)
    df['timestamp'] = pd.to_datetime(df['timestamp'], utc=True)
    
    # è®¡ç®—æ—¶é—´èŒƒå›´
    start_date = df['timestamp'].min()
    end_date = df['timestamp'].max()
    
    print(f"æ•°æ®æ—¶é—´èŒƒå›´: {start_date} åˆ° {end_date}")
    
    splits = []
    current_start = start_date
    
    while current_start < end_date:
        # è®­ç»ƒé›†ç»“æŸæ—¶é—´
        train_end = current_start + pd.Timedelta(days=train_days)
        # æµ‹è¯•é›†ç»“æŸæ—¶é—´
        test_end = train_end + pd.Timedelta(days=test_days)
        
        if test_end > end_date:
            break
            
        # è·å–è®­ç»ƒé›†å’Œæµ‹è¯•é›†ç´¢å¼•
        train_mask = (df['timestamp'] >= current_start) & (df['timestamp'] < train_end)
        test_mask = (df['timestamp'] >= train_end) & (df['timestamp'] < test_end)
        
        train_indices = df[train_mask].index.tolist()
        test_indices = df[test_mask].index.tolist()
        
        # ç¡®ä¿æœ‰è¶³å¤Ÿçš„æ ·æœ¬
        if len(train_indices) >= 1000 and len(test_indices) >= 200:
            splits.append({
                'train_indices': train_indices,
                'test_indices': test_indices,
                'train_start': current_start,
                'train_end': train_end,
                'test_start': train_end,
                'test_end': test_end
            })
        
        # ç§»åŠ¨åˆ°ä¸‹ä¸€ä¸ªåˆ†å‰²ï¼ˆæ»šåŠ¨çª—å£ï¼‰
        current_start = current_start + pd.Timedelta(days=offset_days)
    
    print(f"åˆ›å»ºäº† {len(splits)} ä¸ªwalk-forwardåˆ†å‰²")
    
    # å¦‚æœæ²¡æœ‰åˆ›å»ºåˆ†å‰²ï¼Œä½¿ç”¨ç®€å•çš„æ—¶é—´åˆ†å‰²
    if len(splits) == 0:
        print("ä½¿ç”¨ç®€å•çš„æ—¶é—´åˆ†å‰²...")
        total_samples = len(df)
        train_size = int(total_samples * 0.7)
        test_size = int(total_samples * 0.15)
        
        splits = [{
            'train_indices': list(range(0, train_size)),
            'test_indices': list(range(train_size, train_size + test_size)),
            'train_start': df.iloc[0]['timestamp'],
            'train_end': df.iloc[train_size-1]['timestamp'],
            'test_start': df.iloc[train_size]['timestamp'],
            'test_end': df.iloc[train_size + test_size - 1]['timestamp']
        }]
        print(f"åˆ›å»ºäº† {len(splits)} ä¸ªç®€å•åˆ†å‰²")
    
    return splits

# ---------- è®­ç»ƒæ¨¡å‹ ----------
def train_model(X: pd.DataFrame, y: pd.Series, feature_names: list) -> xgb.XGBClassifier:
    """è®­ç»ƒXGBoostæ¨¡å‹"""
    # æ¨¡å‹å‚æ•°
    params = {
        'max_depth': 4,
        'n_estimators': 200,
        'learning_rate': 0.05,
        'reg_lambda': 1.5,
        'subsample': 0.8,
        'colsample_bytree': 0.8,
        'objective': 'binary:logistic',
        'eval_metric': 'auc',
        'use_label_encoder': False,
        'random_state': 42
    }
    
    model = xgb.XGBClassifier(**params)
    model.fit(X, y, verbose=0)
    
    return model

# ---------- Walk-Forward éªŒè¯ ----------
def walk_forward_validation(df: pd.DataFrame, X: pd.DataFrame, y: pd.Series, feature_names: list):
    """æ‰§è¡Œwalk-forwardéªŒè¯"""
    splits = create_walk_forward_splits(df)
    
    results = []
    
    for i, split in enumerate(splits):
        print(f"\nğŸ”„ åˆ†å‰² {i+1}/{len(splits)}")
        print(f"è®­ç»ƒæœŸ: {split['train_start'].strftime('%Y-%m')} åˆ° {split['train_end'].strftime('%Y-%m')}")
        print(f"æµ‹è¯•æœŸ: {split['test_start'].strftime('%Y-%m')} åˆ° {split['test_end'].strftime('%Y-%m')}")
        
        # è·å–è®­ç»ƒé›†å’Œæµ‹è¯•é›†
        X_train = X.iloc[split['train_indices']]
        y_train = y.iloc[split['train_indices']]
        X_test = X.iloc[split['test_indices']]
        y_test = y.iloc[split['test_indices']]
        
        print(f"è®­ç»ƒæ ·æœ¬: {len(X_train)}, æµ‹è¯•æ ·æœ¬: {len(X_test)}")
        
        # è®­ç»ƒæ¨¡å‹
        model = train_model(X_train, y_train, feature_names)
        
        # é¢„æµ‹
        y_pred_proba = model.predict_proba(X_test)[:, 1]
        auc = roc_auc_score(y_test, y_pred_proba)
        
        # è®¡ç®—å…¶ä»–æŒ‡æ ‡
        y_pred = (y_pred_proba > 0.5).astype(int)
        accuracy = (y_pred == y_test).mean()
        
        # é«˜ç½®ä¿¡åº¦é¢„æµ‹åˆ†æ
        high_conf_mask = (y_pred_proba > 0.7) | (y_pred_proba < 0.3)
        high_conf_accuracy = 0
        if high_conf_mask.sum() > 0:
            high_conf_accuracy = (y_test[high_conf_mask] == (y_pred_proba[high_conf_mask] > 0.5)).mean()
        
        result = {
            'split': i + 1,
            'train_start': split['train_start'],
            'train_end': split['train_end'],
            'test_start': split['test_start'],
            'test_end': split['test_end'],
            'train_samples': len(X_train),
            'test_samples': len(X_test),
            'auc': auc,
            'accuracy': accuracy,
            'high_conf_accuracy': high_conf_accuracy,
            'high_conf_samples': high_conf_mask.sum()
        }
        
        results.append(result)
        
        print(f"AUC: {auc:.4f}, å‡†ç¡®ç‡: {accuracy:.4f}, é«˜ç½®ä¿¡åº¦å‡†ç¡®ç‡: {high_conf_accuracy:.4f}")
    
    return results

# ---------- ç»“æœåˆ†æ ----------
def analyze_walk_forward_results(results: list):
    """åˆ†æwalk-forwardç»“æœ"""
    df_results = pd.DataFrame(results)
    
    print("\nğŸ“Š Walk-Forward éªŒè¯ç»“æœæ±‡æ€»:")
    print("=" * 80)
    print(f"æ€»åˆ†å‰²æ•°: {len(results)}")
    print(f"å¹³å‡AUC: {df_results['auc'].mean():.4f} Â± {df_results['auc'].std():.4f}")
    print(f"å¹³å‡å‡†ç¡®ç‡: {df_results['accuracy'].mean():.4f} Â± {df_results['accuracy'].std():.4f}")
    print(f"å¹³å‡é«˜ç½®ä¿¡åº¦å‡†ç¡®ç‡: {df_results['high_conf_accuracy'].mean():.4f} Â± {df_results['high_conf_accuracy'].std():.4f}")
    print(f"å¹³å‡é«˜ç½®ä¿¡åº¦æ ·æœ¬æ•°: {df_results['high_conf_samples'].mean():.1f}")
    
    print("\nğŸ“ˆ å„åˆ†å‰²è¯¦ç»†ç»“æœ:")
    print(df_results[['split', 'test_start', 'test_end', 'test_samples', 'auc', 'accuracy', 'high_conf_accuracy']].to_string(index=False))
    
    # ä¿å­˜ç»“æœ
    out_csv = DATA_DIR / "walk_forward_15m_results.csv"
    df_results.to_csv(out_csv, index=False)
    print(f"\nç»“æœå·²ä¿å­˜: {out_csv}")
    
    return df_results

# ---------- ä¸»æµç¨‹ ----------
def main():
    print("ğŸ“¥ è¯»å–ç‰¹å¾æ•°æ®...")
    df = pd.read_parquet(FEATURES_FILE)
    print(f"æ•°æ®å½¢çŠ¶: {df.shape}")
    
    # å‡†å¤‡æ•°æ®
    X, y, feature_names, _ = prepare_data(df)
    
    # Walk-ForwardéªŒè¯
    results = walk_forward_validation(df, X, y, feature_names)
    
    # åˆ†æç»“æœ
    df_results = analyze_walk_forward_results(results)
    
    # ä½¿ç”¨æœ€åä¸€ä¸ªåˆ†å‰²çš„æ¨¡å‹ä½œä¸ºæœ€ç»ˆæ¨¡å‹
    if results:
        last_split = results[-1]
        print(f"\nğŸ¯ ä½¿ç”¨æœ€åä¸€ä¸ªåˆ†å‰²è®­ç»ƒæœ€ç»ˆæ¨¡å‹...")
        
        # è·å–æœ€åä¸€ä¸ªåˆ†å‰²çš„è®­ç»ƒæ•°æ®
        splits = create_walk_forward_splits(df)
        last_split_data = splits[-1]
        
        X_final_train = X.iloc[last_split_data['train_indices']]
        y_final_train = y.iloc[last_split_data['train_indices']]
        
        # è®­ç»ƒæœ€ç»ˆæ¨¡å‹
        final_model = train_model(X_final_train, y_final_train, feature_names)
        final_model.save_model(MODEL_FILE)
        print(f"æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜: {MODEL_FILE}")
    
    print("\nğŸ‰ Walk-ForwardéªŒè¯å®Œæˆ!")

if __name__ == "__main__":
    main() 