#!/usr/bin/env python3
"""
RexKing â€“ Enhanced Model Training with Order Flow Features & Calibration

æ•´åˆè®¢å•æµç‰¹å¾é‡æ–°è®­ç»ƒæ¨¡å‹ï¼Œå¹¶è¿›è¡Œæ¦‚ç‡æ ¡å‡†
"""

import pandas as pd
import numpy as np
import xgboost as xgb
from sklearn.model_selection import train_test_split, StratifiedKFold
from sklearn.metrics import roc_auc_score, classification_report, brier_score_loss
from sklearn.calibration import CalibratedClassifierCV
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

# ---------- é…ç½® ----------
DATA_DIR = Path("/Users/qiutianyu/data/processed")
FEATURES_FILE = DATA_DIR / "features_15m_enhanced.parquet"  # ä½¿ç”¨åˆå¹¶åçš„ç‰¹å¾è¡¨
ORDERFLOW_FILE = Path("data/mid_features_15m_orderflow.parquet")
MODEL_FILE = "xgb_15m_enhanced_calibrated.bin"

def create_orderflow_features(df):
    """åˆ›å»ºè®¢å•æµç‰¹å¾ï¼ˆåŸºäºç°æœ‰ç‰¹å¾ï¼‰"""
    print("ğŸ”§ åˆ›å»ºè®¢å•æµç‰¹å¾...")
    
    # åŸºäºç°æœ‰ç‰¹å¾åˆ›å»ºè®¢å•æµç›¸å…³æŒ‡æ ‡
    # ä½¿ç”¨volumeå’Œpriceç›¸å…³ç‰¹å¾
    df['volume_imbalance'] = (df['volume'] - df['volume'].rolling(20).mean()) / (df['volume'].rolling(20).std() + 1e-8)
    df['price_pressure'] = df['price_change'] * df['volume_ratio']
    
    df['liquidity_pressure'] = df['volume_imbalance'] * df['price_pressure']
    df['liquidity_pressure_ma'] = df['liquidity_pressure'].rolling(20).mean()
    
    # ä½¿ç”¨buy_ratioå¦‚æœå­˜åœ¨ï¼Œå¦åˆ™ç”¨å…¶ä»–æŒ‡æ ‡
    if 'buy_ratio' in df.columns:
        df['taker_imbalance'] = (df['buy_ratio'] - 0.5) * 2
    else:
        df['taker_imbalance'] = df['price_change'] * df['volume_ratio']
    df['taker_imbalance_ma'] = df['taker_imbalance'].rolling(20).mean()
    
    df['order_flow_intensity'] = df['price_pressure'] * df['volume_imbalance']
    df['order_flow_intensity_ma'] = df['order_flow_intensity'].rolling(20).mean()
    
    df['liquidity_impact'] = df['price_change'] / (df['volume'] + 1e-8)
    df['liquidity_impact_ma'] = df['liquidity_impact'].rolling(20).mean()
    
    # ä½¿ç”¨volumeç›¸å…³æŒ‡æ ‡
    df['volume_pressure_ratio'] = df['volume'] / (df['volume'].rolling(20).mean() + 1e-8)
    df['volume_pressure_ratio_ma'] = df['volume_pressure_ratio'].rolling(20).mean()
    
    df['order_flow_strength'] = df['order_flow_intensity'] * df['volume_ratio']
    df['order_flow_strength_ma'] = df['order_flow_strength'].rolling(20).mean()
    
    # ä½¿ç”¨spreadç›¸å…³æŒ‡æ ‡
    if 'spread_bps' in df.columns:
        df['liquidity_stress'] = df['liquidity_pressure'] * (df['spread_bps'] / df['spread_bps'].rolling(20).mean())
    else:
        df['liquidity_stress'] = df['liquidity_pressure'] * df['volatility_24']
    df['liquidity_stress_ma'] = df['liquidity_stress'].rolling(20).mean()
    
    if 'spread_bps' in df.columns:
        df['spread_compression'] = df['spread_bps'] / df['spread_bps'].rolling(20).mean()
    else:
        df['spread_compression'] = df['volatility_24'] / df['volatility_24'].rolling(20).mean()
    
    # æ–°å¢ï¼šä»·æ ¼åŠ¨é‡ä¸è®¢å•æµç»“åˆ
    df['price_momentum_flow'] = df['price_momentum'] * df['volume_imbalance']
    df['price_momentum_flow_ma'] = df['price_momentum_flow'].rolling(20).mean()
    
    # æ–°å¢ï¼šæ³¢åŠ¨ç‡ä¸è®¢å•æµç»“åˆ
    df['volatility_flow'] = df['volatility_24'] * df['order_flow_intensity']
    df['volatility_flow_ma'] = df['volatility_flow'].rolling(20).mean()
    
    print(f"âœ… åˆ›å»ºäº† {len([col for col in df.columns if 'flow' in col or 'pressure' in col or 'stress' in col])} ä¸ªè®¢å•æµç‰¹å¾")
    return df

def prepare_enhanced_features(df):
    """å‡†å¤‡å¢å¼ºç‰¹å¾"""
    print("ğŸ“Š å‡†å¤‡å¢å¼ºç‰¹å¾...")
    
    # æ’é™¤éç‰¹å¾åˆ—
    exclude_cols = ['timestamp', 'open', 'high', 'low', 'close', 'volume', 'label', 'trend_1h', 'trend_4h']
    feature_cols = [col for col in df.columns if col not in exclude_cols and pd.api.types.is_numeric_dtype(df[col])]
    
    X = df[feature_cols].fillna(0)
    y = df['label']
    
    print(f"ç‰¹å¾æ•°é‡: {len(feature_cols)}")
    print(f"æ ·æœ¬æ•°é‡: {len(X)}")
    print(f"æ ‡ç­¾åˆ†å¸ƒ: {y.value_counts().to_dict()}")
    
    # æ˜¾ç¤ºè®¢å•æµç‰¹å¾ç»Ÿè®¡
    orderflow_cols = [col for col in feature_cols if any(keyword in col for keyword in ['flow', 'pressure', 'stress', 'imbalance', 'spread', 'liquidity'])]
    print(f"è®¢å•æµç‰¹å¾æ•°é‡: {len(orderflow_cols)}")
    
    # æ£€æŸ¥è®¢å•æµç‰¹å¾çš„éé›¶æ¯”ä¾‹
    if orderflow_cols:
        non_zero_ratio = (X[orderflow_cols] != 0).sum().sum() / (len(X) * len(orderflow_cols))
        print(f"è®¢å•æµç‰¹å¾éé›¶æ¯”ä¾‹: {non_zero_ratio:.2%}")
    
    return X, y, feature_cols

def train_calibrated_model(X, y, feature_cols):
    """è®­ç»ƒæ ¡å‡†åçš„æ¨¡å‹"""
    print("ğŸš€ è®­ç»ƒæ ¡å‡†æ¨¡å‹...")
    
    # åˆ†å‰²æ•°æ®
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
    
    # åŸºç¡€XGBoostå‚æ•°
    base_params = {
        'max_depth': 6,
        'n_estimators': 300,
        'learning_rate': 0.1,
        'subsample': 0.8,
        'colsample_bytree': 0.8,
        'min_child_weight': 3,
        'reg_alpha': 0.1,
        'reg_lambda': 1.0,
        'objective': 'binary:logistic',
        'eval_metric': 'auc',
        'use_label_encoder': False,
        'random_state': 42
    }
    
    # è®­ç»ƒåŸºç¡€æ¨¡å‹
    base_model = xgb.XGBClassifier(**base_params)
    base_model.fit(X_train, y_train, verbose=0)
    
    # æ¦‚ç‡æ ¡å‡†
    print("ğŸ”§ è¿›è¡Œæ¦‚ç‡æ ¡å‡†...")
    calibrated_model = CalibratedClassifierCV(
        base_model, 
        cv=5, 
        method='isotonic',  # ä½¿ç”¨isotonicå›å½’æ ¡å‡†
        n_jobs=-1
    )
    calibrated_model.fit(X_train, y_train)
    
    # è¯„ä¼°
    y_pred_proba_base = base_model.predict_proba(X_test)[:, 1]
    y_pred_proba_cal = calibrated_model.predict_proba(X_test)[:, 1]
    y_pred_base = base_model.predict(X_test)
    y_pred_cal = calibrated_model.predict(X_test)
    
    # åŸºç¡€æ¨¡å‹è¯„ä¼°
    auc_base = roc_auc_score(y_test, y_pred_proba_base)
    brier_base = brier_score_loss(y_test, y_pred_proba_base)
    
    # æ ¡å‡†æ¨¡å‹è¯„ä¼°
    auc_cal = roc_auc_score(y_test, y_pred_proba_cal)
    brier_cal = brier_score_loss(y_test, y_pred_proba_cal)
    
    print(f"åŸºç¡€æ¨¡å‹ AUC: {auc_base:.4f}, Brier Score: {brier_base:.4f}")
    print(f"æ ¡å‡†æ¨¡å‹ AUC: {auc_cal:.4f}, Brier Score: {brier_cal:.4f}")
    
    # é«˜ç½®ä¿¡åº¦é¢„æµ‹å¯¹æ¯”
    high_conf_mask = (y_pred_proba_cal > 0.8) | (y_pred_proba_cal < 0.2)
    if high_conf_mask.sum() > 0:
        high_conf_auc = roc_auc_score(y_test[high_conf_mask], y_pred_proba_cal[high_conf_mask])
        high_conf_acc = (y_pred_cal[high_conf_mask] == y_test[high_conf_mask]).mean()
        print(f"é«˜ç½®ä¿¡åº¦æ ·æœ¬AUC: {high_conf_auc:.4f}")
        print(f"é«˜ç½®ä¿¡åº¦æ ·æœ¬å‡†ç¡®ç‡: {high_conf_acc:.4f}")
        print(f"é«˜ç½®ä¿¡åº¦æ ·æœ¬æ•°é‡: {high_conf_mask.sum()}")
    
    # ç‰¹å¾é‡è¦æ€§
    feature_importance = pd.DataFrame({
        'feature': feature_cols,
        'importance': base_model.feature_importances_
    }).sort_values('importance', ascending=False)
    
    print(f"\nğŸ“Š Top 15 ç‰¹å¾é‡è¦æ€§:")
    for i, row in feature_importance.head(15).iterrows():
        print(f"  {row['feature']}: {row['importance']:.4f}")
    
    # ä¿å­˜æ¨¡å‹
    calibrated_model.save_model(MODEL_FILE)
    print(f"âœ… æ ¡å‡†æ¨¡å‹å·²ä¿å­˜: {MODEL_FILE}")
    
    # ä¿å­˜ç‰¹å¾ä¿¡æ¯
    feature_info = {
        'feature_cols': feature_cols,
        'auc_base': auc_base,
        'auc_calibrated': auc_cal,
        'brier_base': brier_base,
        'brier_calibrated': brier_cal,
        'high_conf_auc': high_conf_auc if high_conf_mask.sum() > 0 else 0,
        'high_conf_acc': high_conf_acc if high_conf_mask.sum() > 0 else 0
    }
    
    import json
    with open('enhanced_model_info.json', 'w') as f:
        json.dump(feature_info, f, indent=2, default=str)
    
    return calibrated_model, base_model, auc_cal, feature_importance

def analyze_calibration_quality(calibrated_model, X_test, y_test):
    """åˆ†ææ ¡å‡†è´¨é‡"""
    print("\nğŸ“ˆ æ ¡å‡†è´¨é‡åˆ†æ...")
    
    y_pred_proba = calibrated_model.predict_proba(X_test)[:, 1]
    
    # åˆ†ç®±åˆ†æ
    n_bins = 10
    bin_edges = np.linspace(0, 1, n_bins + 1)
    bin_indices = np.digitize(y_pred_proba, bin_edges) - 1
    
    calibration_data = []
    for i in range(n_bins):
        mask = bin_indices == i
        if mask.sum() > 0:
            mean_pred = y_pred_proba[mask].mean()
            mean_actual = y_test[mask].mean()
            count = mask.sum()
            calibration_data.append({
                'bin': i,
                'mean_pred': mean_pred,
                'mean_actual': mean_actual,
                'count': count
            })
    
    cal_df = pd.DataFrame(calibration_data)
    print("æ ¡å‡†åˆ†ç®±åˆ†æ:")
    print(cal_df.to_string(index=False, float_format='%.3f'))
    
    # è®¡ç®—æ ¡å‡†è¯¯å·®
    calibration_error = np.mean((cal_df['mean_pred'] - cal_df['mean_actual'])**2)
    print(f"æ ¡å‡†è¯¯å·®: {calibration_error:.4f}")
    
    return cal_df

def main():
    print("=== RexKing Enhanced Model Training with Calibration ===")
    
    # åŠ è½½æ•°æ®
    print("ğŸ“¥ åŠ è½½å¢å¼ºç‰¹å¾æ•°æ®...")
    df = pd.read_parquet(FEATURES_FILE)
    print(f"æ•°æ®è¡Œæ•°: {len(df)}")
    
    # å‡†å¤‡å¢å¼ºç‰¹å¾
    X, y, feature_cols = prepare_enhanced_features(df)
    
    # è®­ç»ƒæ ¡å‡†æ¨¡å‹
    calibrated_model, base_model, auc, feature_importance = train_calibrated_model(X, y, feature_cols)
    
    # åˆ†ææ ¡å‡†è´¨é‡
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
    cal_df = analyze_calibration_quality(calibrated_model, X_test, y_test)
    
    print(f"\nğŸ‰ å¢å¼ºç‰ˆæ¨¡å‹è®­ç»ƒå®Œæˆ!")
    print(f"æœ€ç»ˆæ ¡å‡†AUC: {auc:.4f}")
    print(f"ç‰¹å¾æ•°é‡: {len(feature_cols)}")
    
    return calibrated_model, auc

if __name__ == "__main__":
    main() 