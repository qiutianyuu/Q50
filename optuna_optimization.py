#!/usr/bin/env python3
"""
Optunaè¶…å‚æ•°ä¼˜åŒ– - XGBoost
"""

import pandas as pd
import numpy as np
import xgboost as xgb
from sklearn.model_selection import cross_val_score, StratifiedKFold
from sklearn.metrics import roc_auc_score
import optuna
import warnings
warnings.filterwarnings('ignore')

def optimize_xgb_15m():
    """ä¼˜åŒ–15m XGBoostè¶…å‚æ•°"""
    print("ğŸ”§ ä¼˜åŒ–15m XGBoostè¶…å‚æ•°...")
    
    # è¯»å–æ•°æ®
    df = pd.read_parquet('/Users/qiutianyu/data/processed/features_15m_2023_2025.parquet')
    
    # å‡†å¤‡ç‰¹å¾
    exclude_cols = ['timestamp', 'open', 'high', 'low', 'close', 'volume', 'label', 'trend_1h', 'trend_4h']
    feature_cols = [col for col in df.columns if col not in exclude_cols and pd.api.types.is_numeric_dtype(df[col])]
    
    X = df[feature_cols].fillna(0)
    y = df['label']
    
    print(f"ç‰¹å¾æ•°é‡: {len(feature_cols)}")
    print(f"æ ·æœ¬æ•°é‡: {len(X)}")
    
    def objective(trial):
        # è¶…å‚æ•°æœç´¢ç©ºé—´
        params = {
            'max_depth': trial.suggest_int('max_depth', 3, 8),
            'n_estimators': trial.suggest_int('n_estimators', 100, 500),
            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),
            'subsample': trial.suggest_float('subsample', 0.6, 1.0),
            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),
            'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),
            'reg_alpha': trial.suggest_float('reg_alpha', 0, 10),
            'reg_lambda': trial.suggest_float('reg_lambda', 0, 10),
            'objective': 'binary:logistic',
            'eval_metric': 'auc',
            'use_label_encoder': False,
            'random_state': 42
        }
        
        # 5æŠ˜äº¤å‰éªŒè¯
        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
        scores = []
        
        for train_idx, val_idx in cv.split(X, y):
            X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]
            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]
            
            model = xgb.XGBClassifier(**params)
            model.fit(X_train, y_train, verbose=0)
            
            y_pred_proba = model.predict_proba(X_val)[:, 1]
            auc = roc_auc_score(y_val, y_pred_proba)
            scores.append(auc)
        
        return np.mean(scores)
    
    # åˆ›å»ºstudy
    study = optuna.create_study(direction='maximize')
    study.optimize(objective, n_trials=100, show_progress_bar=True)
    
    print(f"ğŸ¯ æœ€ä½³AUC: {study.best_value:.4f}")
    print(f"æœ€ä½³å‚æ•°: {study.best_params}")
    
    # ä¿å­˜ç»“æœ
    best_params = study.best_params
    best_params.update({
        'objective': 'binary:logistic',
        'eval_metric': 'auc',
        'use_label_encoder': False,
        'random_state': 42
    })
    
    # ä½¿ç”¨æœ€ä½³å‚æ•°è®­ç»ƒæœ€ç»ˆæ¨¡å‹
    final_model = xgb.XGBClassifier(**best_params)
    final_model.fit(X, y, verbose=0)
    
    # ä¿å­˜æ¨¡å‹
    final_model.save_model('xgb_15m_optimized.bin')
    print("âœ… ä¼˜åŒ–åçš„15mæ¨¡å‹å·²ä¿å­˜: xgb_15m_optimized.bin")
    
    return best_params, study.best_value

def optimize_xgb_5m():
    """ä¼˜åŒ–5m XGBoostè¶…å‚æ•°"""
    print("\nğŸ”§ ä¼˜åŒ–5m XGBoostè¶…å‚æ•°...")
    
    # è¯»å–æ•°æ®
    df = pd.read_parquet('/Users/qiutianyu/data/processed/features_5m_2023_2025.parquet')
    
    # å‡†å¤‡ç‰¹å¾
    exclude_cols = ['timestamp', 'open', 'high', 'low', 'close', 'volume', 'label', 'trend_1h', 'trend_4h']
    feature_cols = [col for col in df.columns if col not in exclude_cols and pd.api.types.is_numeric_dtype(df[col])]
    
    X = df[feature_cols].fillna(0)
    y = df['label']
    
    print(f"ç‰¹å¾æ•°é‡: {len(feature_cols)}")
    print(f"æ ·æœ¬æ•°é‡: {len(X)}")
    
    def objective(trial):
        # è¶…å‚æ•°æœç´¢ç©ºé—´
        params = {
            'max_depth': trial.suggest_int('max_depth', 3, 8),
            'n_estimators': trial.suggest_int('n_estimators', 100, 500),
            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),
            'subsample': trial.suggest_float('subsample', 0.6, 1.0),
            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),
            'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),
            'reg_alpha': trial.suggest_float('reg_alpha', 0, 10),
            'reg_lambda': trial.suggest_float('reg_lambda', 0, 10),
            'objective': 'binary:logistic',
            'eval_metric': 'auc',
            'use_label_encoder': False,
            'random_state': 42
        }
        
        # 5æŠ˜äº¤å‰éªŒè¯
        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
        scores = []
        
        for train_idx, val_idx in cv.split(X, y):
            X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]
            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]
            
            model = xgb.XGBClassifier(**params)
            model.fit(X_train, y_train, verbose=0)
            
            y_pred_proba = model.predict_proba(X_val)[:, 1]
            auc = roc_auc_score(y_val, y_pred_proba)
            scores.append(auc)
        
        return np.mean(scores)
    
    # åˆ›å»ºstudy
    study = optuna.create_study(direction='maximize')
    study.optimize(objective, n_trials=50, show_progress_bar=True)  # 5mæ•°æ®é‡å¤§ï¼Œå‡å°‘trialæ•°
    
    print(f"ğŸ¯ æœ€ä½³AUC: {study.best_value:.4f}")
    print(f"æœ€ä½³å‚æ•°: {study.best_params}")
    
    # ä¿å­˜ç»“æœ
    best_params = study.best_params
    best_params.update({
        'objective': 'binary:logistic',
        'eval_metric': 'auc',
        'use_label_encoder': False,
        'random_state': 42
    })
    
    # ä½¿ç”¨æœ€ä½³å‚æ•°è®­ç»ƒæœ€ç»ˆæ¨¡å‹
    final_model = xgb.XGBClassifier(**best_params)
    final_model.fit(X, y, verbose=0)
    
    # ä¿å­˜æ¨¡å‹
    final_model.save_model('xgb_5m_optimized.bin')
    print("âœ… ä¼˜åŒ–åçš„5mæ¨¡å‹å·²ä¿å­˜: xgb_5m_optimized.bin")
    
    return best_params, study.best_value

def main():
    print("ğŸš€ å¼€å§‹Optunaè¶…å‚æ•°ä¼˜åŒ–...")
    
    # ä¼˜åŒ–15mæ¨¡å‹
    best_params_15m, best_auc_15m = optimize_xgb_15m()
    
    # ä¼˜åŒ–5mæ¨¡å‹
    best_params_5m, best_auc_5m = optimize_xgb_5m()
    
    # ç»“æœæ€»ç»“
    print("\nğŸ“Š ä¼˜åŒ–ç»“æœæ€»ç»“:")
    print(f"15mæœ€ä½³AUC: {best_auc_15m:.4f}")
    print(f"5mæœ€ä½³AUC: {best_auc_5m:.4f}")
    
    print("\nğŸ‰ è¶…å‚æ•°ä¼˜åŒ–å®Œæˆ!")

if __name__ == "__main__":
    main() 