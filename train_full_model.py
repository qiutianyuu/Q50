#!/usr/bin/env python3
"""
åŸºäºç¦»çº¿ç‰¹å¾è¿›è¡Œå…¨é‡è®­ç»ƒï¼Œç”Ÿæˆä¿¡å·å¹¶å›æµ‹
"""
import pandas as pd
import numpy as np
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')

# æ•°æ®è·¯å¾„
FEATURES_FILE = "/Users/qiutianyu/features_offline_15m.parquet"
MODEL_FILE = "xgb_full_model.bin"
SIGNALS_FILE = "full_signals.csv"

def load_and_prepare_data():
    """åŠ è½½å’Œå‡†å¤‡æ•°æ®"""
    print("ğŸ“¥ åŠ è½½ç‰¹å¾æ•°æ®...")
    df = pd.read_parquet(FEATURES_FILE)
    print(f"æ•°æ®å½¢çŠ¶: {df.shape}")
    print(f"æ—¶é—´èŒƒå›´: {df['timestamp'].min()} ~ {df['timestamp'].max()}")
    
    # æ’é™¤ä¸éœ€è¦çš„åˆ—
    exclude_cols = ['timestamp', 'open', 'high', 'low', 'close', 'volume', 'close_1h', 'close_4h', 'label']
    feature_cols = [col for col in df.columns if col not in exclude_cols]
    
    print(f"ç‰¹å¾æ•°é‡: {len(feature_cols)}")
    print(f"æ ‡ç­¾åˆ†å¸ƒ: {df['label'].value_counts().to_dict()}")
    
    return df, feature_cols

def train_model(df, feature_cols, test_size=0.2):
    """è®­ç»ƒæ¨¡å‹"""
    print("ğŸ”„ è®­ç»ƒæ¨¡å‹...")
    
    # å‡†å¤‡æ•°æ®
    X = df[feature_cols].fillna(0)
    y = df['label']
    
    # åˆ†å‰²æ•°æ®
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_size, random_state=42, stratify=y
    )
    
    print(f"è®­ç»ƒé›†: {X_train.shape}, æµ‹è¯•é›†: {X_test.shape}")
    
    # è®­ç»ƒæ¨¡å‹
    model = xgb.XGBClassifier(
        n_estimators=200,
        max_depth=6,
        learning_rate=0.1,
        subsample=0.8,
        colsample_bytree=0.8,
        reg_lambda=1,
        random_state=42,
        eval_metric='logloss'
    )
    
    model.fit(X_train, y_train)
    
    # è¯„ä¼°æ¨¡å‹
    y_pred = model.predict(X_test)
    y_proba = model.predict_proba(X_test)
    
    print("\nğŸ“Š åˆ†ç±»æŠ¥å‘Š:")
    print(classification_report(y_test, y_pred))
    
    print("\nğŸ“Š æ··æ·†çŸ©é˜µ:")
    print(confusion_matrix(y_test, y_pred))
    
    # ç‰¹å¾é‡è¦æ€§
    feature_importance = pd.DataFrame({
        'feature': feature_cols,
        'importance': model.feature_importances_
    }).sort_values('importance', ascending=False)
    
    print("\nğŸ“Š ç‰¹å¾é‡è¦æ€§ (å‰15):")
    print(feature_importance.head(15))
    
    return model, X_test, y_test, y_pred, y_proba, feature_importance

def generate_signals(df, model, feature_cols, thresholds=(0.6, 0.4)):
    """ç”Ÿæˆäº¤æ˜“ä¿¡å·"""
    print(f"âš¡ ç”Ÿæˆäº¤æ˜“ä¿¡å·ï¼Œé˜ˆå€¼: {thresholds}")
    
    # å‡†å¤‡ç‰¹å¾
    X = df[feature_cols].fillna(0)
    
    # é¢„æµ‹æ¦‚ç‡
    proba = model.predict_proba(X)
    
    # åˆ›å»ºä¿¡å·DataFrame
    signals = pd.DataFrame({
        'timestamp': df['timestamp'],
        'close': df['close'],
        'prob_down': proba[:, 0],  # ä¸‹è·Œæ¦‚ç‡ (æ ‡ç­¾0)
        'prob_up': proba[:, 1],    # ä¸Šæ¶¨æ¦‚ç‡ (æ ‡ç­¾1) 
        'prob_flat': proba[:, 2] if proba.shape[1] == 3 else 0,  # æ¨ªç›˜æ¦‚ç‡ (æ ‡ç­¾2)
        'prediction': model.predict(X)
    })
    
    # ç”Ÿæˆä¿¡å· (0=ä¸‹è·Œ, 1=ä¸Šæ¶¨, 2=æ¨ªç›˜)
    long_th, short_th = thresholds
    signals['signal'] = 0
    signals.loc[signals['prob_up'] > long_th, 'signal'] = 1  # åšå¤šä¿¡å·
    signals.loc[signals['prob_down'] > short_th, 'signal'] = -1  # åšç©ºä¿¡å·
    
    # è®¡ç®—ä¿¡å·ç»Ÿè®¡
    signal_count = len(signals[signals['signal'] != 0])
    long_signals = len(signals[signals['signal'] == 1])
    short_signals = len(signals[signals['signal'] == -1])
    
    print(f"ğŸ“Š ä¿¡å·ç»Ÿè®¡:")
    print(f"æ€»ä¿¡å·æ•°: {signal_count}")
    print(f"åšå¤šä¿¡å·: {long_signals}")
    print(f"åšç©ºä¿¡å·: {short_signals}")
    
    return signals

def backtest_signals(signals, hold_period=3, fee_rate=0.0004):
    """å›æµ‹ä¿¡å·"""
    print(f"ğŸ“ˆ å›æµ‹ä¿¡å·ï¼ŒæŒä»“æœŸ: {hold_period}æ ¹Kçº¿")
    
    # è®¡ç®—æ¯ç¬”ä¿¡å·çš„å¼€å¹³ä»“ä»·æ ¼
    signals['entry_price'] = signals['close']
    signals['exit_price'] = signals['close'].shift(-hold_period)
    signals['exit_time'] = signals['timestamp'].shift(-hold_period)
    
    # ç§»é™¤æ²¡æœ‰å¹³ä»“ä»·æ ¼çš„ä¿¡å·
    signals = signals.dropna(subset=['exit_price'])
    
    # è®¡ç®—æ”¶ç›Š
    signals['ret'] = (signals['exit_price'] - signals['entry_price']) / signals['entry_price'] * signals['signal']
    signals['ret_net'] = signals['ret'] - fee_rate * 2  # å¼€å¹³å„æ”¶ä¸€æ¬¡æ‰‹ç»­è´¹
    signals['cum_ret'] = (1 + signals['ret_net']).cumprod() - 1
    
    # ç»Ÿè®¡
    win_rate = (signals['ret_net'] > 0).mean()
    avg_ret = signals['ret_net'].mean()
    total_ret = signals['cum_ret'].iloc[-1]
    max_dd = (signals['cum_ret'].cummax() - signals['cum_ret']).max()
    
    print(f"ğŸ“Š å›æµ‹ç»“æœ:")
    print(f"èƒœç‡: {win_rate:.2%}")
    print(f"å¹³å‡å•ç¬”æ”¶ç›Š: {avg_ret:.4%}")
    print(f"ç´¯è®¡æ”¶ç›Š: {total_ret:.2%}")
    print(f"æœ€å¤§å›æ’¤: {max_dd:.2%}")
    print(f"ä¿¡å·åŒºé—´: {signals['timestamp'].min()} ~ {signals['timestamp'].max()}")
    
    return signals

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹å…¨é‡è®­ç»ƒ...")
    
    # åŠ è½½æ•°æ®
    df, feature_cols = load_and_prepare_data()
    
    # è®­ç»ƒæ¨¡å‹
    model, X_test, y_test, y_pred, y_proba, feature_importance = train_model(df, feature_cols)
    
    # ç”Ÿæˆä¿¡å·
    signals = generate_signals(df, model, feature_cols, thresholds=(0.6, 0.4))
    
    # å›æµ‹ä¿¡å·
    backtest_results = backtest_signals(signals, hold_period=3, fee_rate=0.0004)
    
    # ä¿å­˜ç»“æœ
    model.save_model(MODEL_FILE)
    print(f"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜åˆ°: {MODEL_FILE}")
    
    signals.to_csv(SIGNALS_FILE, index=False)
    print(f"ğŸ’¾ ä¿¡å·å·²ä¿å­˜åˆ°: {SIGNALS_FILE}")
    
    feature_importance.to_csv("full_feature_importance.csv", index=False)
    print(f"ğŸ’¾ ç‰¹å¾é‡è¦æ€§å·²ä¿å­˜åˆ°: full_feature_importance.csv")
    
    # æ˜¾ç¤ºä¿¡å·æ ·æœ¬
    print("\nğŸ“Š ä¿¡å·æ ·æœ¬:")
    print(signals[signals['signal'] != 0].head(10))
    
    # ç»˜åˆ¶æ”¶ç›Šæ›²çº¿
    plt.figure(figsize=(12, 6))
    plt.plot(backtest_results['timestamp'], backtest_results['cum_ret'], label='Cumulative Return')
    plt.title('Full Model Backtest Results')
    plt.xlabel('Time')
    plt.ylabel('Cumulative Return')
    plt.legend()
    plt.tight_layout()
    plt.savefig('full_backtest_curve.png')
    print("ğŸ“Š æ”¶ç›Šæ›²çº¿å·²ä¿å­˜ä¸º: full_backtest_curve.png")

if __name__ == "__main__":
    main() 