#!/usr/bin/env python3
"""
RexKing â€“ Feature Engineering 5m (Enhanced with Order Flow)

è¯»å–å·²å¤„ç†çš„ 5m K çº¿ + è®¢å•æµç‰¹å¾, è®¡ç®—æŠ€æœ¯æŒ‡æ ‡ + whale æ»šåŠ¨æŒ‡æ ‡,
ç”ŸæˆäºŒåˆ†ç±»æ ‡ç­¾(ä¸‹ä¸€æ ¹ K çº¿æ¶¨/è·Œ), ä¿å­˜ä¸º Parquet & CSV.
"""

import pandas as pd
import numpy as np
from pathlib import Path
from ta.trend import ADXIndicator, MACD, EMAIndicator
from ta.momentum import RSIIndicator, StochasticOscillator
from ta.volatility import BollingerBands, AverageTrueRange
import glob
import os

# ---------- è·¯å¾„é…ç½® ----------
DATA_DIR = Path("/Users/qiutianyu/data/processed")
KL_FILE  = DATA_DIR / "merged_5m_2023_2025.parquet"
W1_FILE  = Path("/Users/qiutianyu/ETHUSDT-w1/w1_2023_2025.csv")
FUND_OI_FILE = DATA_DIR / "funding_oi_1h.parquet"
LABEL_FILE = DATA_DIR / "label_5m_h12.csv"

def load_latest_order_flow_features():
    """åŠ è½½æœ€æ–°çš„è®¢å•æµç‰¹å¾"""
    files = glob.glob("data/mid_features_5m_*.parquet")
    if not files:
        print("âš ï¸ æœªæ‰¾åˆ°è®¢å•æµç‰¹å¾æ–‡ä»¶ï¼Œè·³è¿‡è®¢å•æµç‰¹å¾")
        return None
    
    latest_file = max(files, key=os.path.getctime)
    print(f"ğŸ“¥ åŠ è½½è®¢å•æµç‰¹å¾: {latest_file}")
    df = pd.read_parquet(latest_file)
    df['timestamp'] = pd.to_datetime(df['timestamp'])
    print(f"âœ… è®¢å•æµç‰¹å¾: {len(df)} è¡Œ")
    return df

# ---------- æŠ€æœ¯æŒ‡æ ‡ ----------
def add_ta_features(df: pd.DataFrame) -> pd.DataFrame:
    hi, lo, close, vol = df["high"], df["low"], df["close"], df["volume"]

    # è¶‹åŠ¿æŒ‡æ ‡
    df["adx_14"]  = ADXIndicator(hi, lo, close, window=14).adx()
    df["rsi_14"]  = RSIIndicator(close, window=14).rsi()

    macd = MACD(close)
    df["macd_diff"] = macd.macd_diff()

    stoch = StochasticOscillator(hi, lo, close, window=14, smooth_window=3)
    df["stoch_k"] = stoch.stoch()
    df["stoch_d"] = stoch.stoch_signal()

    bb = BollingerBands(close, window=20, window_dev=2)
    df["bb_width"]   = (bb.bollinger_hband() - bb.bollinger_lband()) / close
    df["bb_percent"] = bb.bollinger_pband()

    atr = AverageTrueRange(hi, lo, close, window=14)
    df["atr_norm"] = atr.average_true_range() / close

    # åŠ¨é‡æŒ‡æ ‡ (çª—å£ç¼©çŸ­)
    df["ret_1"]  = close.pct_change()
    df["ret_3"]  = close.pct_change(3)
    df["ret_6"]  = close.pct_change(6)
    df["ret_12"] = close.pct_change(12)  # 1å°æ—¶
    df["ret_24"] = close.pct_change(24)  # 2å°æ—¶
    df["ret_72"] = close.pct_change(72)  # 6å°æ—¶
    
    # æ³¢åŠ¨ç‡æŒ‡æ ‡ (çª—å£ç¼©çŸ­)
    df["volatility_10"] = close.pct_change().rolling(10).std()
    df["volatility_24"] = close.pct_change().rolling(24).std()
    df["volatility_72"] = close.pct_change().rolling(72).std()

    # EMA æ–œç‡ (çª—å£ç¼©çŸ­)
    ema_50 = EMAIndicator(close, window=50).ema_indicator()
    ema_200 = EMAIndicator(close, window=200).ema_indicator()
    df["ema_50_slope"] = ema_50.pct_change(12)  # 1å°æ—¶æ–œç‡
    df["ema_200_slope"] = ema_200.pct_change(48)  # 4å°æ—¶æ–œç‡
    df["ema_50_200_ratio"] = ema_50 / ema_200

    # æˆäº¤é‡æŒ‡æ ‡
    df["vol_ma20"] = vol.rolling(20).mean()
    df["vol_ratio"] = vol / df["vol_ma20"]
    df["vol_ma50"] = vol.rolling(50).mean()
    df["vol_ratio_50"] = vol / df["vol_ma50"]

    return df

# ---------- è®¢å•æµç‰¹å¾ ----------
def add_order_flow_features(df: pd.DataFrame, order_flow_df: pd.DataFrame) -> pd.DataFrame:
    """æ·»åŠ è®¢å•æµç‰¹å¾"""
    if order_flow_df is None:
        print("âš ï¸ è·³è¿‡è®¢å•æµç‰¹å¾")
        return df
    
    print("ğŸ“Š æ·»åŠ è®¢å•æµç‰¹å¾...")
    
    # ç¡®ä¿æ—¶é—´æˆ³æ ¼å¼ä¸€è‡´ - éƒ½è½¬æ¢ä¸ºUTC
    df['timestamp'] = pd.to_datetime(df['timestamp'], utc=True)
    order_flow_df['timestamp'] = pd.to_datetime(order_flow_df['timestamp'], utc=True)
    
    # ä½¿ç”¨merge_asofè¿›è¡Œæ—¶é—´å¯¹é½
    df = pd.merge_asof(
        df.sort_values('timestamp'),
        order_flow_df.sort_values('timestamp'),
        on='timestamp',
        direction='backward',
        suffixes=('', '_of')
    )
    
    # é€‰æ‹©é‡è¦çš„è®¢å•æµç‰¹å¾
    order_flow_cols = [
        # ä»·æ ¼åŠ¨é‡
        'price_momentum_1m', 'price_momentum_3m', 'price_momentum_5m',
        
        # æˆäº¤é‡ç‰¹å¾
        'volume_ratio', 'volume_ma_3m', 'volume_ma_5m',
        
        # ä»·å·®ç‰¹å¾
        'spread_ratio', 'spread_trend', 'spread_ma', 'spread_std',
        
        # è®¢å•æµç‰¹å¾
        'imbalance_trend', 'pressure_trend', 'volume_imbalance_ma',
        'bid_ask_imbalance', 'price_pressure_ma', 'price_pressure_std',
        
        # æµåŠ¨æ€§ç‰¹å¾
        'liquidity_trend', 'fill_prob_trend', 'liquidity_score', 'liquidity_ma',
        'bid_fill_prob', 'ask_fill_prob', 'bid_price_impact', 'ask_price_impact',
        
        # æ³¢åŠ¨ç‡ç‰¹å¾
        'volatility_ma', 'volatility_ratio', 'price_volatility',
        
        # å¼‚å¸¸æ£€æµ‹
        'price_jump', 'volume_spike', 'spread_widening',
        
        # VWAPç‰¹å¾
        'vwap_deviation', 'vwap_deviation_ma',
        
        # å…¶ä»–é‡è¦ç‰¹å¾
        'buy_ratio', 'price_trend', 'trend_deviation',
        'price_impact_imbalance', 'fill_prob_imbalance'
    ]
    
    # åªä¿ç•™å­˜åœ¨çš„åˆ—
    available_cols = [col for col in order_flow_cols if col in order_flow_df.columns]
    print(f"âœ… ä½¿ç”¨ {len(available_cols)} ä¸ªè®¢å•æµç‰¹å¾")
    
    # å¡«å……NaN
    for col in available_cols:
        if col in df.columns:
            df[col] = df[col].fillna(0)
    
    return df

# ---------- æ—¶é—´ç‰¹å¾ ----------
def add_time_features(df: pd.DataFrame) -> pd.DataFrame:
    df["hour"] = df["timestamp"].dt.hour
    df["weekday"] = df["timestamp"].dt.weekday
    df["month"] = df["timestamp"].dt.month
    
    # æ—¶é—´å‘¨æœŸç‰¹å¾
    df["is_asia_session"] = ((df["hour"] >= 0) & (df["hour"] < 8)).astype(int)
    df["is_london_session"] = ((df["hour"] >= 8) & (df["hour"] < 16)).astype(int)
    df["is_ny_session"] = ((df["hour"] >= 13) & (df["hour"] < 21)).astype(int)
    
    return df

# ---------- Funding & OI ç‰¹å¾ ----------
def add_funding_oi_features(df: pd.DataFrame) -> pd.DataFrame:
    if FUND_OI_FILE.exists():
        f = pd.read_parquet(FUND_OI_FILE)
        f['timestamp'] = pd.to_datetime(f['timestamp'], utc=True)
        
        # Funding z-scoreï¼ˆæ»šåŠ¨7å¤©ï¼‰
        f['funding_z'] = (
            (f['funding'] - f['funding'].rolling(168).mean())
            / f['funding'].rolling(168).std()
        )
        
        # æŒ‰å°æ—¶å…ˆforward-fillå†merge_asof
        df = pd.merge_asof(
            df.sort_values('timestamp'),
            f.sort_values('timestamp'),
            on='timestamp', direction='backward'
        )
        
        # OIå˜åŒ–ç‡ (5m)
        df['oi_chg_6h'] = f['oi'].pct_change(72)
        df['oi_chg_24h'] = f['oi'].pct_change(288)
        
        # å¡«å……NaN
        df[['funding_z', 'oi_chg_6h', 'oi_chg_24h']] = df[['funding_z', 'oi_chg_6h', 'oi_chg_24h']].fillna(0)
    else:
        # æ–‡ä»¶ä¸å­˜åœ¨æ—¶å¡«0
        df[['funding_z', 'oi_chg_6h', 'oi_chg_24h']] = 0
    return df

# ---------- Whale ä¿¡å· (å¢å¼ºç‰ˆ) ----------
def add_whale_features(df: pd.DataFrame) -> pd.DataFrame:
    # åˆå§‹åŒ–æ‰€æœ‰whaleç‰¹å¾ä¸º0
    whale_cols = ["w1_zscore", "w1_cnt_6h", "w1_cnt_12h", "w1_cnt_24h", 
                  "w1_val_6h", "w1_val_12h", "w1_val_24h",
                  "w1_cnt_6h_norm", "w1_val_6h_norm", "whale_dir", 
                  "whale_dir_6h", "whale_dir_12h"]
    for col in whale_cols:
        df[col] = 0
    
    if W1_FILE.exists():
        w1 = pd.read_csv(W1_FILE, parse_dates=["timestamp"])
        w1["timestamp"] = pd.to_datetime(w1["timestamp"], utc=True)
        
        # æ£€æŸ¥whaleæ•°æ®æ˜¯å¦è¶³å¤Ÿ
        if len(w1) > 10:  # è‡³å°‘éœ€è¦10ä¸ªæ•°æ®ç‚¹
            df = df.merge(
                w1[["timestamp", "count", "value", "w1_zscore"]],
                on="timestamp", how="left"
            )

            df[["count", "value", "w1_zscore"]] = df[["count", "value", "w1_zscore"]].fillna(0)
            
            # æ»šåŠ¨çª—å£ (5m)
            df["w1_cnt_6h"]   = df["count"].rolling(72, min_periods=1).sum()   # 6å°æ—¶ (72æ ¹5m)
            df["w1_cnt_12h"]  = df["count"].rolling(144, min_periods=1).sum()  # 12å°æ—¶ (144æ ¹5m)
            df["w1_cnt_24h"]  = df["count"].rolling(288, min_periods=1).sum()  # 24å°æ—¶ (288æ ¹5m)
            
            df["w1_val_6h"]   = df["value"].rolling(72, min_periods=1).sum()
            df["w1_val_12h"]  = df["value"].rolling(144, min_periods=1).sum()
            df["w1_val_24h"]  = df["value"].rolling(288, min_periods=1).sum()
            
            # æ ‡å‡†åŒ–
            df["w1_cnt_6h_norm"] = df["w1_cnt_6h"] / df["w1_cnt_6h"].rolling(288).mean()
            df["w1_val_6h_norm"] = df["w1_val_6h"] / df["w1_val_6h"].rolling(288).mean()
            
            # Whale direction (5m)
            df["whale_dir"] = np.sign(df["value"])
            df["whale_dir_6h"] = df["whale_dir"].rolling(72, min_periods=1).sum()
            df["whale_dir_12h"] = df["whale_dir"].rolling(144, min_periods=1).sum()
        else:
            print(f"âš ï¸ Whaleæ•°æ®ä¸è¶³ ({len(w1)}è¡Œ)ï¼Œä½¿ç”¨é»˜è®¤å€¼")
    else:
        print("âš ï¸ Whaleæ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤å€¼")
    
    return df

# ---------- æ ‡ç­¾ ----------
def add_label(df: pd.DataFrame) -> pd.DataFrame:
    """ä½¿ç”¨å¤–éƒ¨labelæ–‡ä»¶"""
    if LABEL_FILE.exists():
        label_df = pd.read_csv(LABEL_FILE)
        label_df['timestamp'] = pd.to_datetime(label_df['timestamp'], utc=True)
        
        # åˆå¹¶label
        df = df.merge(label_df[['timestamp', 'label']], on='timestamp', how='left')
        
        # åªä¿ç•™æœ‰äº¤æ˜“ä¿¡å·çš„æ ·æœ¬ï¼ˆlabel != -1ï¼‰
        df = df[df['label'] != -1].reset_index(drop=True)
        
        print(f"âœ… ä½¿ç”¨å¤–éƒ¨labelï¼Œä¿ç•™äº¤æ˜“ä¿¡å·æ ·æœ¬: {len(df)}")
    else:
        print("âš ï¸ å¤–éƒ¨labelæ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤æ ‡ç­¾")
        df["label"] = (df["close"].shift(-1) > df["close"]).astype(int)
    
    return df

# ---------- ä¸»æµç¨‹ ----------
def main():
    print(f"ğŸ“¥ è¯»å– {KL_FILE.name} ...")
    df = pd.read_parquet(KL_FILE)
    # ä¿®æ­£ dtype æ£€æŸ¥ï¼Œå…¼å®¹ pandas æ‰©å±•ç±»å‹
    if not pd.api.types.is_datetime64_any_dtype(df["timestamp"]):
        df["timestamp"] = pd.to_datetime(df["timestamp"], utc=True)
    df = df.sort_values("timestamp").reset_index(drop=True)

    print("âœ¨ è®¡ç®—æŠ€æœ¯æŒ‡æ ‡ ...")
    df = add_ta_features(df)

    print("ğŸ“Š åŠ è½½è®¢å•æµç‰¹å¾ ...")
    order_flow_df = load_latest_order_flow_features()
    
    print("ğŸ”— é›†æˆè®¢å•æµç‰¹å¾ ...")
    df = add_order_flow_features(df, order_flow_df)

    print("â° æ·»åŠ æ—¶é—´ç‰¹å¾ ...")
    df = add_time_features(df)

    print("ğŸ³ æ•´åˆ whale æŒ‡æ ‡ ...")
    df = add_whale_features(df)

    print("ğŸ’° æ•´åˆ funding & OI æŒ‡æ ‡ ...")
    df = add_funding_oi_features(df)

    print("ğŸ·ï¸ æ·»åŠ æ ‡ç­¾ ...")
    df = add_label(df)

    # æ¸…ç†æ•°æ®
    print("ğŸ§¹ æ¸…ç†æ•°æ® ...")
    df = df.dropna(subset=["label"]).reset_index(drop=True)
    
    # ç§»é™¤æ— ç©·å¤§å€¼
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    df[numeric_cols] = df[numeric_cols].replace([np.inf, -np.inf], np.nan)
    df = df.fillna(0)

    print(f"âœ… æœ€ç»ˆæ•°æ®: {len(df)} è¡Œ, {len(df.columns)} åˆ—")
    print(f"ğŸ“Š æ ‡ç­¾åˆ†å¸ƒ: {df['label'].value_counts().to_dict()}")

    # ä¿å­˜ç»“æœ
    timestamp = pd.Timestamp.now().strftime("%Y%m%d_%H%M%S")
    output_file = f"data/features_5m_enhanced_{timestamp}.parquet"
    df.to_parquet(output_file, index=False)
    print(f"ğŸ’¾ ä¿å­˜åˆ°: {output_file}")

    # ä¿å­˜ç‰¹å¾åˆ—è¡¨
    feature_cols = [col for col in df.columns if col not in ['timestamp', 'label']]
    feature_list = {
        'features': feature_cols,
        'total_features': len(feature_cols),
        'order_flow_features': len([col for col in feature_cols if any(x in col for x in ['momentum', 'volume_', 'spread_', 'imbalance', 'pressure', 'liquidity', 'jump', 'spike'])]),
        'technical_features': len([col for col in feature_cols if any(x in col for x in ['adx', 'rsi', 'macd', 'stoch', 'bb', 'atr', 'ema', 'ret_', 'volatility'])]),
        'whale_features': len([col for col in feature_cols if col.startswith('w1_') or col.startswith('whale_')]),
        'time_features': len([col for col in feature_cols if col in ['hour', 'weekday', 'month', 'is_asia_session', 'is_london_session', 'is_ny_session']]),
        'funding_oi_features': len([col for col in feature_cols if col.startswith('funding_') or col.startswith('oi_')])
    }
    
    feature_list_file = f"data/feature_list_5m_enhanced_{timestamp}.json"
    import json
    with open(feature_list_file, 'w') as f:
        json.dump(feature_list, f, indent=2)
    print(f"ğŸ“‹ ç‰¹å¾åˆ—è¡¨ä¿å­˜åˆ°: {feature_list_file}")

if __name__ == "__main__":
    main() 