#!/usr/bin/env python3
"""
ä½¿ç”¨Walk-Forwardä¼˜åŒ–çš„æœ€ä½³å‚æ•°é‡æ–°è®­ç»ƒæ¨¡å‹
"""
import pandas as pd
import numpy as np
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')

# æ•°æ®è·¯å¾„
FEATURES_FILE = "/Users/qiutianyu/features_offline_15m.parquet"
MODEL_FILE = "xgb_optimized_model.bin"
SIGNALS_FILE = "optimized_signals.csv"

# Walk-Forwardä¼˜åŒ–çš„æœ€ä½³å‚æ•°
BEST_PARAMS = {
    'conservative': {
        'long_threshold': 0.7,    # æé«˜åšå¤šé˜ˆå€¼
        'short_threshold': 0.7,   # æé«˜åšç©ºé˜ˆå€¼
        'hold_period': 4,
        'name': 'Conservative'
    },
    'aggressive': {
        'long_threshold': 0.8,
        'short_threshold': 0.8,   # æé«˜åšç©ºé˜ˆå€¼
        'hold_period': 5,
        'name': 'Aggressive'
    }
}

def load_and_prepare_data():
    """åŠ è½½å’Œå‡†å¤‡æ•°æ®"""
    print("ğŸ“¥ åŠ è½½ç‰¹å¾æ•°æ®...")
    df = pd.read_parquet(FEATURES_FILE)
    print(f"æ•°æ®å½¢çŠ¶: {df.shape}")
    print(f"æ—¶é—´èŒƒå›´: {df['timestamp'].min()} ~ {df['timestamp'].max()}")
    
    # æ’é™¤ä¸éœ€è¦çš„åˆ—
    exclude_cols = ['timestamp', 'open', 'high', 'low', 'close', 'volume', 'close_1h', 'close_4h', 'label']
    feature_cols = [col for col in df.columns if col not in exclude_cols]
    
    print(f"ç‰¹å¾æ•°é‡: {len(feature_cols)}")
    print(f"æ ‡ç­¾åˆ†å¸ƒ: {df['label'].value_counts().to_dict()}")
    
    return df, feature_cols

def train_optimized_model(df, feature_cols, test_size=0.2):
    """è®­ç»ƒä¼˜åŒ–æ¨¡å‹"""
    print("ğŸ”„ è®­ç»ƒä¼˜åŒ–æ¨¡å‹...")
    
    # å‡†å¤‡æ•°æ®
    X = df[feature_cols].fillna(0)
    y = df['label']
    
    # åˆ†å‰²æ•°æ®
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_size, random_state=42, stratify=y
    )
    
    print(f"è®­ç»ƒé›†: {X_train.shape}, æµ‹è¯•é›†: {X_test.shape}")
    
    # è®­ç»ƒæ¨¡å‹ï¼ˆä½¿ç”¨æ›´ä¿å®ˆçš„å‚æ•°ï¼‰
    model = xgb.XGBClassifier(
        n_estimators=200,
        max_depth=6,
        learning_rate=0.1,
        subsample=0.8,
        colsample_bytree=0.8,
        reg_lambda=2,  # å¢åŠ æ­£åˆ™åŒ–
        random_state=42,
        eval_metric='logloss'
    )
    
    model.fit(X_train, y_train)
    
    # è¯„ä¼°æ¨¡å‹
    y_pred = model.predict(X_test)
    y_proba = model.predict_proba(X_test)
    
    print("\nğŸ“Š åˆ†ç±»æŠ¥å‘Š:")
    print(classification_report(y_test, y_pred))
    
    print("\nğŸ“Š æ··æ·†çŸ©é˜µ:")
    print(confusion_matrix(y_test, y_pred))
    
    # ç‰¹å¾é‡è¦æ€§
    feature_importance = pd.DataFrame({
        'feature': feature_cols,
        'importance': model.feature_importances_
    }).sort_values('importance', ascending=False)
    
    print("\nğŸ“Š ç‰¹å¾é‡è¦æ€§ (å‰15):")
    print(feature_importance.head(15))
    
    return model, X_test, y_test, y_pred, y_proba, feature_importance

def generate_optimized_signals(df, model, feature_cols, strategy_params):
    """ç”Ÿæˆä¼˜åŒ–ä¿¡å·"""
    print(f"âš¡ ç”Ÿæˆ{strategy_params['name']}ç­–ç•¥ä¿¡å·...")
    print(f"é˜ˆå€¼: ({strategy_params['long_threshold']}, {strategy_params['short_threshold']})")
    
    # å‡†å¤‡ç‰¹å¾
    X = df[feature_cols].fillna(0)
    
    # é¢„æµ‹æ¦‚ç‡
    proba = model.predict_proba(X)
    
    # åˆ›å»ºä¿¡å·DataFrame
    signals = pd.DataFrame({
        'timestamp': df['timestamp'],
        'close': df['close'],
        'prob_down': proba[:, 0],  # ä¸‹è·Œæ¦‚ç‡ (æ ‡ç­¾0)
        'prob_up': proba[:, 1],    # ä¸Šæ¶¨æ¦‚ç‡ (æ ‡ç­¾1) 
        'prob_flat': proba[:, 2],  # æ¨ªç›˜æ¦‚ç‡ (æ ‡ç­¾2)
        'prediction': model.predict(X)
    })
    
    # ç”Ÿæˆä¿¡å· - ä¿®å¤é€»è¾‘
    long_th = strategy_params['long_threshold']
    short_th = strategy_params['short_threshold']
    
    signals['signal'] = 0
    # åšå¤šï¼šä¸Šæ¶¨æ¦‚ç‡ > é˜ˆå€¼ ä¸” ä¸Šæ¶¨æ¦‚ç‡ > ä¸‹è·Œæ¦‚ç‡
    long_condition = (signals['prob_up'] > long_th) & (signals['prob_up'] > signals['prob_down'])
    signals.loc[long_condition, 'signal'] = 1
    
    # åšç©ºï¼šä¸‹è·Œæ¦‚ç‡ > é˜ˆå€¼ ä¸” ä¸‹è·Œæ¦‚ç‡ > ä¸Šæ¶¨æ¦‚ç‡  
    short_condition = (signals['prob_down'] > short_th) & (signals['prob_down'] > signals['prob_up'])
    signals.loc[short_condition, 'signal'] = -1
    
    # è®¡ç®—ä¿¡å·ç»Ÿè®¡
    signal_count = len(signals[signals['signal'] != 0])
    long_signals = len(signals[signals['signal'] == 1])
    short_signals = len(signals[signals['signal'] == -1])
    
    print(f"ğŸ“Š ä¿¡å·ç»Ÿè®¡:")
    print(f"æ€»ä¿¡å·æ•°: {signal_count}")
    print(f"åšå¤šä¿¡å·: {long_signals}")
    print(f"åšç©ºä¿¡å·: {short_signals}")
    
    return signals

def backtest_optimized_signals(signals, strategy_params, fee_rate=0.0004):
    """å›æµ‹ä¼˜åŒ–ä¿¡å·"""
    print(f"ğŸ“ˆ å›æµ‹{strategy_params['name']}ç­–ç•¥...")
    
    hold_period = strategy_params['hold_period']
    
    # åªå¯¹æœ‰ä¿¡å·çš„æ ·æœ¬è¿›è¡Œå›æµ‹
    signal_samples = signals[signals['signal'] != 0].copy()
    
    if len(signal_samples) == 0:
        print("âš ï¸ æ²¡æœ‰ç”Ÿæˆä»»ä½•ä¿¡å·")
        return signals, {
            'win_rate': 0,
            'total_ret': 0,
            'annual_ret': 0,
            'max_dd': 0,
            'sharpe': 0,
            'signal_count': 0
        }
    
    # è®¡ç®—æ¯ç¬”ä¿¡å·çš„å¼€å¹³ä»“ä»·æ ¼
    signal_samples['entry_price'] = signal_samples['close']
    signal_samples['exit_price'] = signal_samples['close'].shift(-hold_period)
    signal_samples['exit_time'] = signal_samples['timestamp'].shift(-hold_period)
    
    # ç§»é™¤æ²¡æœ‰å¹³ä»“ä»·æ ¼çš„ä¿¡å·
    signal_samples = signal_samples.dropna(subset=['exit_price'])
    
    if len(signal_samples) == 0:
        print("âš ï¸ æ‰€æœ‰ä¿¡å·éƒ½æ²¡æœ‰å®Œæ•´çš„å¹³ä»“ä»·æ ¼")
        return signals, {
            'win_rate': 0,
            'total_ret': 0,
            'annual_ret': 0,
            'max_dd': 0,
            'sharpe': 0,
            'signal_count': 0
        }
    
    # è®¡ç®—æ”¶ç›Š
    signal_samples['ret'] = (signal_samples['exit_price'] - signal_samples['entry_price']) / signal_samples['entry_price'] * signal_samples['signal']
    signal_samples['ret_net'] = signal_samples['ret'] - fee_rate * 2  # å¼€å¹³å„æ”¶ä¸€æ¬¡æ‰‹ç»­è´¹
    
    # ç»Ÿè®¡
    win_rate = (signal_samples['ret_net'] > 0).mean()
    avg_ret = signal_samples['ret_net'].mean()
    
    # è®¡ç®—ç´¯è®¡æ”¶ç›Šï¼ˆä½¿ç”¨å¤åˆ©è®¡ç®—ï¼‰
    signal_samples['cum_ret'] = (1 + signal_samples['ret_net']).cumprod() - 1
    total_ret = signal_samples['cum_ret'].iloc[-1]
    max_dd = (signal_samples['cum_ret'].cummax() - signal_samples['cum_ret']).max()
    
    # è®¡ç®—å¹´åŒ–æ”¶ç›Šå’Œå¤æ™®æ¯”
    days = (signal_samples['timestamp'].max() - signal_samples['timestamp'].min()).days
    annual_ret = (1 + total_ret) ** (365 / days) - 1 if days > 0 else 0
    sharpe = avg_ret / (signal_samples['ret_net'].std() + 1e-8) * np.sqrt(252 * 96)  # 96ä¸ª15åˆ†é’Ÿ/å¤©
    
    print(f"ğŸ“Š {strategy_params['name']}ç­–ç•¥å›æµ‹ç»“æœ:")
    print(f"æœ‰æ•ˆä¿¡å·æ•°: {len(signal_samples)}")
    print(f"èƒœç‡: {win_rate:.2%}")
    print(f"å¹³å‡å•ç¬”æ”¶ç›Š: {avg_ret:.4%}")
    print(f"ç´¯è®¡æ”¶ç›Š: {total_ret:.2%}")
    print(f"å¹´åŒ–æ”¶ç›Š: {annual_ret:.2%}")
    print(f"æœ€å¤§å›æ’¤: {max_dd:.2%}")
    print(f"å¤æ™®æ¯”: {sharpe:.2f}")
    print(f"ä¿¡å·åŒºé—´: {signal_samples['timestamp'].min()} ~ {signal_samples['timestamp'].max()}")
    
    return signal_samples, {
        'win_rate': win_rate,
        'total_ret': total_ret,
        'annual_ret': annual_ret,
        'max_dd': max_dd,
        'sharpe': sharpe,
        'signal_count': len(signal_samples)
    }

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹ä¼˜åŒ–æ¨¡å‹è®­ç»ƒ...")
    
    # åŠ è½½æ•°æ®
    df, feature_cols = load_and_prepare_data()
    
    # è®­ç»ƒæ¨¡å‹
    model, X_test, y_test, y_pred, y_proba, feature_importance = train_optimized_model(df, feature_cols)
    
    # æµ‹è¯•ä¸¤ç§ç­–ç•¥
    results = {}
    
    for strategy_name, params in BEST_PARAMS.items():
        print(f"\n{'='*50}")
        print(f"æµ‹è¯• {params['name']} ç­–ç•¥")
        print(f"{'='*50}")
        
        # ç”Ÿæˆä¿¡å·
        signals = generate_optimized_signals(df, model, feature_cols, params)
        
        # å›æµ‹ä¿¡å·
        backtest_signals, stats = backtest_optimized_signals(signals, params)
        
        # ä¿å­˜ç»“æœ
        signals.to_csv(f"{strategy_name}_signals.csv", index=False)
        print(f"ğŸ’¾ {params['name']}ä¿¡å·å·²ä¿å­˜åˆ°: {strategy_name}_signals.csv")
        
        results[strategy_name] = stats
    
    # ä¿å­˜æ¨¡å‹å’Œç‰¹å¾é‡è¦æ€§
    model.save_model(MODEL_FILE)
    print(f"ğŸ’¾ ä¼˜åŒ–æ¨¡å‹å·²ä¿å­˜åˆ°: {MODEL_FILE}")
    
    feature_importance.to_csv("optimized_feature_importance.csv", index=False)
    print(f"ğŸ’¾ ç‰¹å¾é‡è¦æ€§å·²ä¿å­˜åˆ°: optimized_feature_importance.csv")
    
    # ç­–ç•¥å¯¹æ¯”
    print(f"\n{'='*60}")
    print("ğŸ“Š ç­–ç•¥å¯¹æ¯”")
    print(f"{'='*60}")
    
    comparison_df = pd.DataFrame(results).T
    print(comparison_df.round(4))
    
    # æ¨èç­–ç•¥
    best_strategy = max(results.keys(), key=lambda x: results[x]['sharpe'])
    print(f"\nğŸ† æ¨èç­–ç•¥: {BEST_PARAMS[best_strategy]['name']}")
    print(f"å¤æ™®æ¯”: {results[best_strategy]['sharpe']:.2f}")
    print(f"å¹´åŒ–æ”¶ç›Š: {results[best_strategy]['annual_ret']:.2%}")
    print(f"æœ€å¤§å›æ’¤: {results[best_strategy]['max_dd']:.2%}")
    
    # ç»˜åˆ¶æ”¶ç›Šæ›²çº¿å¯¹æ¯”
    plt.figure(figsize=(15, 8))
    
    for strategy_name, params in BEST_PARAMS.items():
        signals = pd.read_csv(f"{strategy_name}_signals.csv")
        signals['timestamp'] = pd.to_datetime(signals['timestamp'])
        
        # è®¡ç®—ç´¯è®¡æ”¶ç›Š
        hold_period = params['hold_period']
        signals['entry_price'] = signals['close']
        signals['exit_price'] = signals['close'].shift(-hold_period)
        signals = signals.dropna(subset=['exit_price'])
        
        signals['ret'] = (signals['exit_price'] - signals['entry_price']) / signals['entry_price'] * signals['signal']
        signals['ret_net'] = signals['ret'] - 0.0004 * 2
        signals['cum_ret'] = (1 + signals['ret_net']).cumprod() - 1
        
        plt.plot(signals['timestamp'], signals['cum_ret'], label=f"{params['name']} (Sharpe: {results[strategy_name]['sharpe']:.2f})")
    
    plt.title('Strategy Comparison - Cumulative Returns')
    plt.xlabel('Time')
    plt.ylabel('Cumulative Return')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.savefig('strategy_comparison.png', dpi=300, bbox_inches='tight')
    print("ğŸ“Š ç­–ç•¥å¯¹æ¯”å›¾å·²ä¿å­˜ä¸º: strategy_comparison.png")

if __name__ == "__main__":
    main() 