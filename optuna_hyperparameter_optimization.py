#!/usr/bin/env python3
"""
Optunaè¶…å‚æ•°ä¼˜åŒ– - ä½¿ç”¨ç­›é€‰åçš„ç‰¹å¾ä¼˜åŒ–XGBoostæ¨¡å‹
"""

import optuna
import pandas as pd
import numpy as np
import xgboost as xgb
from sklearn.model_selection import TimeSeriesSplit
from sklearn.metrics import roc_auc_score
import warnings
warnings.filterwarnings('ignore')

def load_data(features_path, labels_path):
    """åŠ è½½æ•°æ®"""
    print(f"ğŸ“ åŠ è½½ç‰¹å¾: {features_path}")
    features_df = pd.read_parquet(features_path)
    
    print(f"ğŸ“ åŠ è½½æ ‡ç­¾: {labels_path}")
    labels_df = pd.read_csv(labels_path)
    
    # ç¡®ä¿timestampåˆ—ç±»å‹ä¸€è‡´
    features_df['timestamp'] = pd.to_datetime(features_df['timestamp'])
    labels_df['timestamp'] = pd.to_datetime(labels_df['timestamp'])
    
    # ç§»é™¤æ—¶åŒºä¿¡æ¯ä»¥ç¡®ä¿åŒ¹é…
    features_df['timestamp'] = features_df['timestamp'].dt.tz_localize(None)
    labels_df['timestamp'] = labels_df['timestamp'].dt.tz_localize(None)
    
    # åˆå¹¶æ•°æ®
    df = features_df.merge(labels_df[['timestamp', 'label']], on='timestamp', how='inner')
    
    # å‡†å¤‡ç‰¹å¾å’Œæ ‡ç­¾
    feature_cols = [col for col in df.columns if col not in 
                   ['timestamp', 'open', 'high', 'low', 'close', 'volume', 'date', 'label']]
    
    X = df[feature_cols].fillna(0)
    y = df['label']
    
    # è½¬æ¢æ ‡ç­¾ä¸ºäºŒè¿›åˆ¶æ ¼å¼ (-1 -> 0, 1 -> 1)
    y = (y == 1).astype(int)
    
    print(f"ğŸ“Š æ•°æ®å½¢çŠ¶: {X.shape}")
    print(f"ğŸ“Š ç‰¹å¾æ•°é‡: {len(feature_cols)}")
    print(f"ğŸ“Š æ ‡ç­¾åˆ†å¸ƒ: {y.value_counts().to_dict()}")
    
    return X, y, feature_cols

def objective(trial, X, y, n_splits=5):
    """Optunaç›®æ ‡å‡½æ•°"""
    
    # è¶…å‚æ•°æœç´¢ç©ºé—´
    params = {
        'objective': 'binary:logistic',
        'eval_metric': 'auc',
        'random_state': 42,
        'n_jobs': -1,
        
        # æ ¸å¿ƒå‚æ•°
        'max_depth': trial.suggest_int('max_depth', 3, 10),
        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),
        'n_estimators': trial.suggest_int('n_estimators', 50, 500),
        
        # æ­£åˆ™åŒ–å‚æ•°
        'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True),
        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),
        'subsample': trial.suggest_float('subsample', 0.6, 1.0),
        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),
        'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.6, 1.0),
        
        # å…¶ä»–å‚æ•°
        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),
        'gamma': trial.suggest_float('gamma', 1e-8, 1.0, log=True),
        'scale_pos_weight': trial.suggest_float('scale_pos_weight', 0.5, 2.0),
    }
    
    # æ—¶é—´åºåˆ—äº¤å‰éªŒè¯
    tscv = TimeSeriesSplit(n_splits=n_splits)
    scores = []
    
    for train_idx, val_idx in tscv.split(X):
        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]
        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]
        
        # è®­ç»ƒæ¨¡å‹
        model = xgb.XGBClassifier(**params, early_stopping_rounds=50)
        model.fit(
            X_train, y_train,
            eval_set=[(X_val, y_val)],
            verbose=False
        )
        
        # é¢„æµ‹å’Œè¯„ä¼°
        y_pred = model.predict_proba(X_val)[:, 1]
        score = roc_auc_score(y_val, y_pred)
        scores.append(score)
    
    return np.mean(scores)

def optimize_hyperparameters(X, y, n_trials=100, timeout=3600):
    """ä¼˜åŒ–è¶…å‚æ•°"""
    print(f"ğŸ” å¼€å§‹è¶…å‚æ•°ä¼˜åŒ–...")
    print(f"ğŸ“Š è¯•éªŒæ¬¡æ•°: {n_trials}")
    print(f"â±ï¸ è¶…æ—¶æ—¶é—´: {timeout}ç§’")
    
    study = optuna.create_study(
        direction='maximize',
        sampler=optuna.samplers.TPESampler(seed=42)
    )
    
    study.optimize(
        lambda trial: objective(trial, X, y),
        n_trials=n_trials,
        timeout=timeout,
        show_progress_bar=True
    )
    
    print(f"âœ… ä¼˜åŒ–å®Œæˆ!")
    print(f"ğŸ† æœ€ä½³AUC: {study.best_value:.4f}")
    print(f"ğŸ¯ æœ€ä½³å‚æ•°:")
    for key, value in study.best_params.items():
        print(f"  {key}: {value}")
    
    return study

def train_final_model(X, y, best_params, output_path):
    """è®­ç»ƒæœ€ç»ˆæ¨¡å‹"""
    print("ğŸš€ è®­ç»ƒæœ€ç»ˆæ¨¡å‹...")
    
    # ä½¿ç”¨æœ€ä½³å‚æ•°è®­ç»ƒæ¨¡å‹
    final_model = xgb.XGBClassifier(**best_params, random_state=42)
    final_model.fit(X, y)
    
    # ä¿å­˜æ¨¡å‹
    final_model.save_model(output_path)
    print(f"âœ… æ¨¡å‹å·²ä¿å­˜: {output_path}")
    
    return final_model

def main():
    print("ğŸš€ Optunaè¶…å‚æ•°ä¼˜åŒ–")
    
    # ä¼˜åŒ–15mæ¨¡å‹
    print("\nğŸ“Š ä¼˜åŒ–15mæ¨¡å‹...")
    X_15m, y_15m, feature_cols_15m = load_data(
        'data/features_15m_selected.parquet',
        'data/label_15m_cost.csv'
    )
    
    study_15m = optimize_hyperparameters(X_15m, y_15m, n_trials=50, timeout=1800)
    
    # è®­ç»ƒæœ€ç»ˆ15mæ¨¡å‹
    final_model_15m = train_final_model(
        X_15m, y_15m, 
        study_15m.best_params,
        'xgb_15m_optuna_optimized.bin'
    )
    
    # ä¿å­˜ä¼˜åŒ–ç»“æœ
    optuna_results_15m = {
        'best_auc': study_15m.best_value,
        'best_params': study_15m.best_params,
        'n_trials': len(study_15m.trials),
        'feature_cols': feature_cols_15m
    }
    
    import json
    with open('optuna_results_15m.json', 'w') as f:
        json.dump(optuna_results_15m, f, indent=2, default=str)
    
    # ä¼˜åŒ–5mæ¨¡å‹
    print("\nğŸ“Š ä¼˜åŒ–5mæ¨¡å‹...")
    X_5m, y_5m, feature_cols_5m = load_data(
        'data/features_5m_selected.parquet',
        'data/label_5m_cost.csv'
    )
    
    study_5m = optimize_hyperparameters(X_5m, y_5m, n_trials=50, timeout=1800)
    
    # è®­ç»ƒæœ€ç»ˆ5mæ¨¡å‹
    final_model_5m = train_final_model(
        X_5m, y_5m,
        study_5m.best_params,
        'xgb_5m_optuna_optimized.bin'
    )
    
    # ä¿å­˜ä¼˜åŒ–ç»“æœ
    optuna_results_5m = {
        'best_auc': study_5m.best_value,
        'best_params': study_5m.best_params,
        'n_trials': len(study_5m.trials),
        'feature_cols': feature_cols_5m
    }
    
    with open('optuna_results_5m.json', 'w') as f:
        json.dump(optuna_results_5m, f, indent=2, default=str)
    
    print("\nâœ… è¶…å‚æ•°ä¼˜åŒ–å®Œæˆï¼")

if __name__ == "__main__":
    main() 