#!/usr/bin/env python3
"""
åˆå¹¶è®¢å•æµç‰¹å¾åˆ°ä¸»ç‰¹å¾è¡¨
"""

import pandas as pd
import numpy as np
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

def merge_orderflow_features():
    """åˆå¹¶è®¢å•æµç‰¹å¾åˆ°ä¸»ç‰¹å¾è¡¨"""
    print("ğŸ”„ åˆå¹¶è®¢å•æµç‰¹å¾...")
    
    # åŠ è½½ä¸»ç‰¹å¾è¡¨
    main_file = Path("/Users/qiutianyu/data/processed/features_15m_2023_2025.parquet")
    orderflow_file = Path("data/mid_features_15m_orderflow.parquet")
    
    print(f"ğŸ“¥ åŠ è½½ä¸»ç‰¹å¾è¡¨: {main_file}")
    main = pd.read_parquet(main_file)
    print(f"ä¸»è¡¨å½¢çŠ¶: {main.shape}")
    
    print(f"ğŸ“¥ åŠ è½½è®¢å•æµç‰¹å¾: {orderflow_file}")
    orderflow = pd.read_parquet(orderflow_file)
    print(f"è®¢å•æµè¡¨å½¢çŠ¶: {orderflow.shape}")
    
    # ç¡®ä¿æ—¶é—´æˆ³æ ¼å¼ä¸€è‡´
    main['timestamp'] = pd.to_datetime(main['timestamp'], utc=True)
    orderflow['timestamp'] = pd.to_datetime(orderflow['timestamp'], utc=True)
    
    print(f"ä¸»è¡¨æ—¶é—´èŒƒå›´: {main['timestamp'].min()} åˆ° {main['timestamp'].max()}")
    print(f"è®¢å•æµæ—¶é—´èŒƒå›´: {orderflow['timestamp'].min()} åˆ° {orderflow['timestamp'].max()}")
    
    # é€‰æ‹©é«˜ä¿¡æ¯å¯†åº¦çš„è®¢å•æµç‰¹å¾
    exclude_cols = ['timestamp', 'mid_price', 'bid_price', 'ask_price', 'vwap', 'price_mean', 'price_std', 'price_range']
    orderflow_cols = [col for col in orderflow.columns if col not in exclude_cols]
    
    print(f"ğŸ“Š é€‰æ‹© {len(orderflow_cols)} ä¸ªè®¢å•æµç‰¹å¾:")
    for col in orderflow_cols:
        print(f"  - {col}")
    
    # åˆå¹¶ç‰¹å¾
    print("ğŸ”— æ‰§è¡Œç‰¹å¾åˆå¹¶...")
    merged = pd.merge_asof(
        main.sort_values('timestamp'),
        orderflow[['timestamp'] + orderflow_cols].sort_values('timestamp'),
        on='timestamp', direction='backward'
    )
    
    print(f"åˆå¹¶åå½¢çŠ¶: {merged.shape}")
    
    # å¡«å……NaNå€¼
    print("ğŸ”§ å¡«å……ç¼ºå¤±å€¼...")
    merged[orderflow_cols] = merged[orderflow_cols].fillna(0)
    
    # æ£€æŸ¥åˆå¹¶ç»“æœ
    print("ğŸ“Š æ£€æŸ¥åˆå¹¶ç»“æœ...")
    print(f"ä¸»è¡¨ç‰¹å¾æ•°: {len([col for col in main.columns if col not in ['timestamp', 'open', 'high', 'low', 'close', 'volume', 'label']])}")
    print(f"æ–°å¢ç‰¹å¾æ•°: {len(orderflow_cols)}")
    print(f"æ€»ç‰¹å¾æ•°: {len([col for col in merged.columns if col not in ['timestamp', 'open', 'high', 'low', 'close', 'volume', 'label']])}")
    
    # æ£€æŸ¥æ—¶é—´å¯¹é½
    print("â° æ£€æŸ¥æ—¶é—´å¯¹é½...")
    merged_sorted = merged.sort_values('timestamp')
    time_gaps = merged_sorted['timestamp'].diff().dt.total_seconds() / 900  # 15åˆ†é’Ÿ
    print(f"æ—¶é—´é—´éš”ç»Ÿè®¡: å¹³å‡={time_gaps.mean():.2f}ä¸ª15åˆ†é’Ÿ, æœ€å¤§={time_gaps.max():.2f}")
    
    # ä¿å­˜åˆå¹¶åçš„ç‰¹å¾è¡¨
    output_file = Path("/Users/qiutianyu/data/processed/features_15m_enhanced.parquet")
    merged.to_parquet(output_file, index=False)
    print(f"âœ… åˆå¹¶åçš„ç‰¹å¾è¡¨å·²ä¿å­˜: {output_file}")
    
    # æ˜¾ç¤ºæ–°å¢ç‰¹å¾çš„å‰å‡ è¡Œ
    print("\nğŸ“ˆ æ–°å¢ç‰¹å¾æ ·æœ¬:")
    sample_cols = orderflow_cols[:10]  # æ˜¾ç¤ºå‰10ä¸ªç‰¹å¾
    print(merged[['timestamp'] + sample_cols].head())
    
    return merged, orderflow_cols

def main():
    print("=== è®¢å•æµç‰¹å¾åˆå¹¶ ===")
    
    merged_df, orderflow_features = merge_orderflow_features()
    
    print(f"\nğŸ‰ åˆå¹¶å®Œæˆ!")
    print(f"æœ€ç»ˆç‰¹å¾è¡¨: {merged_df.shape[0]} è¡Œ, {merged_df.shape[1]} åˆ—")
    print(f"æ–°å¢è®¢å•æµç‰¹å¾: {len(orderflow_features)} ä¸ª")
    
    return merged_df, orderflow_features

if __name__ == "__main__":
    main() 