#!/usr/bin/env python3
"""
äº‹ä»¶ç³»ç»Ÿæµ‹è¯•è„šæœ¬ - éªŒè¯äº‹ä»¶æ£€æµ‹å’Œæ ‡ç­¾ç”ŸæˆåŠŸèƒ½
"""

import pandas as pd
import numpy as np
from pathlib import Path
import subprocess
import sys
import warnings
from datetime import datetime

warnings.filterwarnings('ignore')

def test_event_detection():
    """æµ‹è¯•äº‹ä»¶æ£€æµ‹åŠŸèƒ½"""
    print("ğŸ” æµ‹è¯•äº‹ä»¶æ£€æµ‹ç³»ç»Ÿ...")
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    input_file = "data/features_15m_enhanced.parquet"
    if not Path(input_file).exists():
        print(f"âš ï¸ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_file}")
        print("è¯·å…ˆè¿è¡Œç‰¹å¾å·¥ç¨‹è„šæœ¬ç”Ÿæˆç‰¹å¾æ–‡ä»¶")
        return False
    
    # è¿è¡Œäº‹ä»¶æ£€æµ‹
    output_file = "data/events_15m.parquet"
    cmd = [
        sys.executable, "detect_events.py",
        "--input", input_file,
        "--output", output_file
    ]
    
    try:
        result = subprocess.run(cmd, capture_output=True, text=True, check=True)
        print("âœ… äº‹ä»¶æ£€æµ‹æˆåŠŸ!")
        print(result.stdout)
        
        # éªŒè¯è¾“å‡ºæ–‡ä»¶
        if Path(output_file).exists():
            df = pd.read_parquet(output_file)
            print(f"ğŸ“Š äº‹ä»¶æ–‡ä»¶ç»Ÿè®¡:")
            print(f"  æ ·æœ¬æ•°: {len(df):,}")
            print(f"  ç‰¹å¾æ•°: {len(df.columns)}")
            
            # æ£€æŸ¥äº‹ä»¶ç‰¹å¾
            event_features = [col for col in df.columns if any(event_type in col for event_type in 
                            ['breakout', 'reversal', 'spike', 'cross', 'oversold', 'overbought', 'whale_'])]
            print(f"  äº‹ä»¶ç‰¹å¾æ•°: {len(event_features)}")
            
            # æ£€æŸ¥èšåˆç‰¹å¾
            if 'event_strength' in df.columns:
                print(f"  äº‹ä»¶å¼ºåº¦èŒƒå›´: {df['event_strength'].min():.3f} åˆ° {df['event_strength'].max():.3f}")
            if 'event_density' in df.columns:
                print(f"  äº‹ä»¶å¯†åº¦èŒƒå›´: {df['event_density'].min():.0f} åˆ° {df['event_density'].max():.0f}")
            
            return True
        else:
            print("âŒ äº‹ä»¶æ£€æµ‹è¾“å‡ºæ–‡ä»¶ä¸å­˜åœ¨")
            return False
            
    except subprocess.CalledProcessError as e:
        print(f"âŒ äº‹ä»¶æ£€æµ‹å¤±è´¥: {e}")
        print(f"é”™è¯¯è¾“å‡º: {e.stderr}")
        return False

def test_label_generation():
    """æµ‹è¯•æ ‡ç­¾ç”ŸæˆåŠŸèƒ½"""
    print("\nğŸ·ï¸ æµ‹è¯•æ ‡ç­¾ç”Ÿæˆç³»ç»Ÿ...")
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    input_file = "data/events_15m.parquet"
    if not Path(input_file).exists():
        print(f"âš ï¸ äº‹ä»¶æ–‡ä»¶ä¸å­˜åœ¨: {input_file}")
        print("è¯·å…ˆè¿è¡Œäº‹ä»¶æ£€æµ‹è„šæœ¬")
        return False
    
    # æµ‹è¯•ä¸åŒçš„æ ‡ç­¾ç­–ç•¥
    strategies = ['event_strength', 'event_combination', 'event_sequential']
    
    for strategy in strategies:
        print(f"\nğŸ¯ æµ‹è¯•ç­–ç•¥: {strategy}")
        
        output_file = f"data/labels_15m_{strategy}.parquet"
        cmd = [
            sys.executable, "label_events.py",
            "--input", input_file,
            "--output", output_file,
            "--strategy", strategy,
            "--min_strength", "0.2",
            "--max_strength", "0.9",
            "--min_density", "2",
            "--hold_period", "4",
            "--min_profit", "0.0005",
            "--max_loss", "-0.0015"
        ]
        
        try:
            result = subprocess.run(cmd, capture_output=True, text=True, check=True)
            print(f"âœ… {strategy} æ ‡ç­¾ç”ŸæˆæˆåŠŸ!")
            
            # éªŒè¯è¾“å‡ºæ–‡ä»¶
            if Path(output_file).exists():
                df = pd.read_parquet(output_file)
                print(f"ğŸ“Š {strategy} æ ‡ç­¾ç»Ÿè®¡:")
                print(f"  æ ·æœ¬æ•°: {len(df):,}")
                
                if 'label' in df.columns:
                    label_counts = df['label'].value_counts()
                    print(f"  æ ‡ç­¾åˆ†å¸ƒ: {label_counts.to_dict()}")
                    
                    # è®¡ç®—äº¤æ˜“ä¿¡å·æ¯”ä¾‹
                    trade_signals = (df['label'] != -1).sum()
                    trade_ratio = trade_signals / len(df) * 100
                    print(f"  äº¤æ˜“ä¿¡å·æ¯”ä¾‹: {trade_ratio:.1f}%")
                    
                    # åˆ†ææ”¶ç›Š
                    if 'net_return' in df.columns:
                        trade_mask = df['label'] != -1
                        if trade_mask.sum() > 0:
                            trade_returns = df.loc[trade_mask, 'net_return']
                            print(f"  å¹³å‡å‡€æ”¶ç›Š: {trade_returns.mean():.6f}")
                            print(f"  æ­£æ”¶ç›Šæ¯”ä¾‹: {(trade_returns > 0).sum() / len(trade_returns)*100:.1f}%")
            
        except subprocess.CalledProcessError as e:
            print(f"âŒ {strategy} æ ‡ç­¾ç”Ÿæˆå¤±è´¥: {e}")
            print(f"é”™è¯¯è¾“å‡º: {e.stderr}")
            continue
    
    return True

def test_integration():
    """æµ‹è¯•å®Œæ•´æµç¨‹é›†æˆ"""
    print("\nğŸ”„ æµ‹è¯•å®Œæ•´æµç¨‹é›†æˆ...")
    
    # æ£€æŸ¥æ‰€æœ‰å¿…è¦çš„æ–‡ä»¶
    required_files = [
        "data/features_15m_enhanced.parquet",
        "data/events_15m.parquet",
        "data/labels_15m_event_strength.parquet"
    ]
    
    missing_files = [f for f in required_files if not Path(f).exists()]
    
    if missing_files:
        print(f"âš ï¸ ç¼ºå°‘æ–‡ä»¶: {missing_files}")
        return False
    
    # åŠ è½½æ•°æ®å¹¶éªŒè¯ä¸€è‡´æ€§
    try:
        features_df = pd.read_parquet("data/features_15m_enhanced.parquet")
        events_df = pd.read_parquet("data/events_15m.parquet")
        labels_df = pd.read_parquet("data/labels_15m_event_strength.parquet")
        
        print("ğŸ“Š æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥:")
        print(f"  ç‰¹å¾æ•°æ®æ ·æœ¬æ•°: {len(features_df):,}")
        print(f"  äº‹ä»¶æ•°æ®æ ·æœ¬æ•°: {len(events_df):,}")
        print(f"  æ ‡ç­¾æ•°æ®æ ·æœ¬æ•°: {len(labels_df):,}")
        
        # æ£€æŸ¥æ—¶é—´æˆ³ä¸€è‡´æ€§
        if len(features_df) == len(events_df) == len(labels_df):
            print("âœ… æ•°æ®é•¿åº¦ä¸€è‡´")
        else:
            print("âŒ æ•°æ®é•¿åº¦ä¸ä¸€è‡´")
            return False
        
        # æ£€æŸ¥æ—¶é—´æˆ³å¯¹é½
        features_timestamps = set(features_df['timestamp'])
        events_timestamps = set(events_df['timestamp'])
        labels_timestamps = set(labels_df['timestamp'])
        
        if features_timestamps == events_timestamps == labels_timestamps:
            print("âœ… æ—¶é—´æˆ³å¯¹é½")
        else:
            print("âŒ æ—¶é—´æˆ³ä¸å¯¹é½")
            return False
        
        # éªŒè¯äº‹ä»¶ç‰¹å¾
        event_features = [col for col in events_df.columns if any(event_type in col for event_type in 
                        ['breakout', 'reversal', 'spike', 'cross', 'oversold', 'overbought', 'whale_'])]
        print(f"  æ£€æµ‹åˆ°çš„äº‹ä»¶ç‰¹å¾: {len(event_features)}")
        
        # éªŒè¯æ ‡ç­¾è´¨é‡
        if 'label' in labels_df.columns:
            trade_signals = (labels_df['label'] != -1).sum()
            print(f"  ç”Ÿæˆçš„äº¤æ˜“ä¿¡å·: {trade_signals:,}")
            
            if trade_signals > 0:
                print("âœ… æˆåŠŸç”Ÿæˆäº¤æ˜“ä¿¡å·")
            else:
                print("âš ï¸ æœªç”Ÿæˆäº¤æ˜“ä¿¡å·ï¼Œå¯èƒ½éœ€è¦è°ƒæ•´å‚æ•°")
        
        return True
        
    except Exception as e:
        print(f"âŒ é›†æˆæµ‹è¯•å¤±è´¥: {e}")
        return False

def generate_test_report():
    """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
    print("\nğŸ“‹ ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š...")
    
    report = {
        "test_time": datetime.now().isoformat(),
        "event_detection": False,
        "label_generation": False,
        "integration": False,
        "summary": []
    }
    
    # è¿è¡Œæµ‹è¯•
    if test_event_detection():
        report["event_detection"] = True
        report["summary"].append("âœ… äº‹ä»¶æ£€æµ‹æµ‹è¯•é€šè¿‡")
    else:
        report["summary"].append("âŒ äº‹ä»¶æ£€æµ‹æµ‹è¯•å¤±è´¥")
    
    if test_label_generation():
        report["label_generation"] = True
        report["summary"].append("âœ… æ ‡ç­¾ç”Ÿæˆæµ‹è¯•é€šè¿‡")
    else:
        report["summary"].append("âŒ æ ‡ç­¾ç”Ÿæˆæµ‹è¯•å¤±è´¥")
    
    if test_integration():
        report["integration"] = True
        report["summary"].append("âœ… é›†æˆæµ‹è¯•é€šè¿‡")
    else:
        report["summary"].append("âŒ é›†æˆæµ‹è¯•å¤±è´¥")
    
    # ä¿å­˜æŠ¥å‘Š
    report_file = "test_report.json"
    import json
    with open(report_file, 'w') as f:
        json.dump(report, f, indent=2)
    
    print(f"ğŸ“ æµ‹è¯•æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
    
    # æ‰“å°æ€»ç»“
    print("\nğŸ¯ æµ‹è¯•æ€»ç»“:")
    for summary in report["summary"]:
        print(f"  {summary}")
    
    if all([report["event_detection"], report["label_generation"], report["integration"]]):
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡! äº‹ä»¶ç³»ç»Ÿå‡†å¤‡å°±ç»ª")
    else:
        print("\nâš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç›¸å…³è„šæœ¬å’Œé…ç½®")

def main():
    print("ğŸ§ª RexKing äº‹ä»¶ç³»ç»Ÿæµ‹è¯•")
    print("=" * 50)
    
    # æ£€æŸ¥å¿…è¦æ–‡ä»¶
    required_scripts = ["detect_events.py", "label_events.py"]
    missing_scripts = [s for s in required_scripts if not Path(s).exists()]
    
    if missing_scripts:
        print(f"âŒ ç¼ºå°‘å¿…è¦è„šæœ¬: {missing_scripts}")
        return
    
    print("âœ… æ‰€æœ‰å¿…è¦è„šæœ¬å­˜åœ¨")
    
    # è¿è¡Œæµ‹è¯•
    generate_test_report()

if __name__ == "__main__":
    main() 