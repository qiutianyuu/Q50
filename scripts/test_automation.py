#!/usr/bin/env python3
"""
è‡ªåŠ¨åŒ–æµç¨‹æµ‹è¯•è„šæœ¬
éªŒè¯æ•´ä¸ªæµæ°´çº¿æ˜¯å¦æ­£å¸¸å·¥ä½œ
"""

import subprocess
import sys
import os
import json
import yaml

def run_command(cmd, description):
    """è¿è¡Œå‘½ä»¤å¹¶æ£€æŸ¥ç»“æœ"""
    print(f"\nğŸ”„ {description}")
    print(f"æ‰§è¡Œ: {cmd}")
    
    try:
        result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
        if result.returncode == 0:
            print(f"âœ… {description} æˆåŠŸ")
            if result.stdout:
                print(f"è¾“å‡º: {result.stdout[:200]}...")
            return True
        else:
            print(f"âŒ {description} å¤±è´¥")
            print(f"é”™è¯¯: {result.stderr}")
            return False
    except Exception as e:
        print(f"âŒ {description} å¼‚å¸¸: {e}")
        return False

def test_pipeline():
    """æµ‹è¯•æ•´ä¸ªæµæ°´çº¿"""
    print("ğŸš€ å¼€å§‹æµ‹è¯•è‡ªåŠ¨åŒ–æµæ°´çº¿")
    
    # 1. æ£€æŸ¥æ•°æ®
    success = run_command(
        "python scripts/data_pipeline.py --check-only",
        "æ•°æ®ç®¡é“æ£€æŸ¥"
    )
    if not success:
        return False
    
    # 2. ç”Ÿæˆæ ‡ç­¾
    success = run_command(
        "python generate_micro_labels.py --horizon 120 --alpha 0.3 --mode maker --require-fill --output test_labels.parquet",
        "ç”Ÿæˆæ ‡ç­¾"
    )
    if not success:
        return False
    
    # 3. è®­ç»ƒæ¨¡å‹
    success = run_command(
        "python train_micro_xgb.py --features test_labels.parquet --model-out test_model.bin --label-col label_h120_a0.3_maker",
        "è®­ç»ƒæ¨¡å‹"
    )
    if not success:
        return False
    
    # 4. å›æµ‹
    success = run_command(
        "python micro_backtest_maker.py --model test_model.bin --features test_labels.parquet --json-out test_results.json",
        "æ‰§è¡Œå›æµ‹"
    )
    if not success:
        return False
    
    # 5. é€‰æ‹©æœ€ä½³å‚æ•°
    success = run_command(
        "python scripts/select_best.py test_results.json --metric sharpe --output test_best.yaml",
        "é€‰æ‹©æœ€ä½³å‚æ•°"
    )
    if not success:
        return False
    
    # 6. éªŒè¯è¾“å‡ºæ–‡ä»¶
    print("\nğŸ“‹ éªŒè¯è¾“å‡ºæ–‡ä»¶:")
    
    files_to_check = [
        ("test_labels.parquet", "æ ‡ç­¾æ–‡ä»¶"),
        ("test_model.bin", "æ¨¡å‹æ–‡ä»¶"),
        ("test_results.json", "å›æµ‹ç»“æœ"),
        ("test_best.yaml", "æœ€ä½³å‚æ•°")
    ]
    
    for filename, description in files_to_check:
        if os.path.exists(filename):
            print(f"âœ… {description}: {filename}")
            if filename.endswith('.json'):
                with open(filename, 'r') as f:
                    data = json.load(f)
                    print(f"   åŒ…å« {len(data)} ä¸ªç»“æœ")
            elif filename.endswith('.yaml'):
                with open(filename, 'r') as f:
                    data = yaml.safe_load(f)
                    print(f"   æœ€ä½³Sharpe: {data.get('sharpe', 'N/A')}")
        else:
            print(f"âŒ {description}: {filename} ä¸å­˜åœ¨")
            return False
    
    print("\nğŸ‰ è‡ªåŠ¨åŒ–æµæ°´çº¿æµ‹è¯•å®Œæˆï¼")
    return True

def cleanup():
    """æ¸…ç†æµ‹è¯•æ–‡ä»¶"""
    test_files = [
        "test_labels.parquet",
        "test_model.bin", 
        "test_results.json",
        "test_best.yaml"
    ]
    
    for file in test_files:
        if os.path.exists(file):
            os.remove(file)
            print(f"ğŸ—‘ï¸  æ¸…ç†: {file}")

if __name__ == "__main__":
    if len(sys.argv) > 1 and sys.argv[1] == "--cleanup":
        cleanup()
    else:
        success = test_pipeline()
        if success:
            print("\nâœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼Œå¯ä»¥éƒ¨ç½²åˆ° GitHub Actions")
        else:
            print("\nâŒ æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")
            sys.exit(1) 